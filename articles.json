{
  "last_updated": "2026-02-23T22:43:57.219730+00:00",
  "articles": [
    {
      "title": "Uber’s new autonomous vehicle division is about survival and opportunity",
      "link": "https://techcrunch.com/2026/02/23/uber-autonomous-solutions-av-robotaxi/",
      "author": "Kirsten Korosec",
      "date": "2026-02-23T11:54:22-08:00",
      "image": "https://techcrunch.com/wp-content/uploads/2025/10/uber-lucid.jpg?resize=1200,801",
      "category": "Transportation",
      "content": "Uber has a pitch for autonomous vehicle makers: we got this.\n\nThe ride-hailing and food delivery company has launched a new division called Uber Autonomous Solutions designed to take on all the tasks associated with operating a robotaxi, self-driving truck, or sidewalk delivery robot business, including software and support services.\n\nThe initiative, announced Monday, formalizes what Uber has been not so quietly working on for several years now.\n\nUber has amassed partnerships with nearly two dozen autonomous vehicle technology companies across every use case from robotaxis and trucking to sidewalk delivery robots and drones. Uber has backed many of these companies —Lucid and Nuro,Waabi, and China’sWeRide— invested $100 million to build fast-charging, autonomous-vehicle charging stations, and even launchedUber AV Labs, a specialized engineering team that will gather data for robotaxi partners.\n\nUber has made the partnerships and investments; now it wants to make itself indispensable.\n\n“AV tech teams should be able to focus on what they do best: building software that can safely power an autonomous world,” said Sarfraz Maredia, Uber’s global head of autonomous mobility and delivery, who will be leading the initiative. The idea, he said, is to add “operational depth wherever they need it,” including demand generation, rider experience, customer support, or managing the day-to-day fleet operations.\n\nThe end goal is to help these companies reduce their costs per mile and increase the speed to market. Uber said it plans to help these partners scale robotaxi deployments tomore than 15 cities by the end of this year.\n\n“What’s going to determine the success or failure of autonomous in the world is whether it can be commercialized, and Uber is going to be the thing that makes autonomy commercially viable,” Uber President and COO Andrew MacDonald said.\n\nFor Uber that means handling infrastructure like training data and mapping, fleet financing, regulatory services, and managing how robotaxis and other AVs navigate complex events and venues. The company said it is using a fleet of specially equipped Lucid vehicles to collect data that can be shared with partners so they can train their AI systems.\n\nThe new division also plans to tackle user experience including customer support. Notably, Uber wants to take over fleet management, which would include remote assistance — an issue that recently received attention from federal lawmakers over concernsWaymo uses workers overseas. Fleet management would also cover insurance and employing the humans who might need to support these AVs when they’re out in the world.\n\nUber’s move is both existential and opportunistic. The company sold its in-house AV development unit known as Uber ATG in 2020, following two years of internal struggles and pressure after one of its test vehicles killed a pedestrian. (Uber sold off the division in acomplex deal with Aurora.)\n\nIt has tried to shore up its position through partnerships and investments. And there have been plenty. Uber and Waymo have a shared robotaxi service in Atlanta and Austin. The company has also locked up partnerships with Chinese firms Baidu, Momenta, and Pony.ai, sidewalk delivery bot companies Cartken, Starship, Serve, and the UK-based automated driving tech startup Wayve, as well as robotaxi developers AVride and Motional, to name a few. It has plans to launch a robotaxi service with Volkswagen in Los Angeles by the end of 2026 — although it won’t be driverless until 2027.\n\nThese do provide Uber with some protection, but it doesn’t provide a replacement to any revenue lost if these companies erode its own ride-hailing and food delivery business that is today powered by human drivers. Uber is hoping this new division will.\n\nLoading the player…",
      "excerpt": "Uber has a pitch for autonomous vehicle makers: we got this.\n\nThe ride-hailing and food delivery company has launched a new division called Uber Autonomous Solutions designed to take on all the tasks associated with operating a robotaxi, self-driving truck, or sidewalk delivery robot business, inclu",
      "tags": [
        "Apple",
        "Amazon",
        "Cloud Computing",
        "EVs",
        "Google"
      ]
    },
    {
      "title": "Anthropic accuses Chinese AI labs of mining Claude as US debates AI chip exports",
      "link": "https://techcrunch.com/2026/02/23/anthropic-accuses-chinese-ai-labs-of-mining-claude-as-us-debates-ai-chip-exports/",
      "author": "Rebecca Bellan",
      "date": "2026-02-23T11:57:27-08:00",
      "image": "https://techcrunch.com/wp-content/uploads/2026/02/GettyImages-2262515136.jpg?w=1024",
      "category": "AI",
      "content": "Anthropic isaccusingthree Chinese AI companies of setting up more than 24,000 fake accounts with its Claude AI model to improve their own models.\n\nThe labs —DeepSeek,Moonshot AI, andMiniMax— allegedly generated more than 16 million exchanges with Claude through those accounts using a technique called “distillation.” Anthropic said the labs “targeted Claude’s most differentiated capabilities: agentic reasoning, tool use, and coding.”\n\nThe accusations come amid debates over how strictly to enforce export controls on advanced AI chips, a policy aimed at curbing China’s AI development.\n\nDistillation is a common training method that AI labs use on their own models to create smaller, cheaper versions, but competitors can use it to essentially copy the homework of other labs. OpenAI sent a memo to House lawmakers earlier this month accusing DeepSeek of using distillation to mimic its products.\n\nDeepSeek firstmade wavesa year ago when it released its open-source R1 reasoning model that nearly matched American frontier labs in performance at a fraction of the cost. DeepSeek is expected to soon release DeepSeek V4, its latest model, whichreportedlycan outperform Anthropic’s Claude and OpenAI’s ChatGPT in coding.\n\nThe scale of each attack differed in scope. Anthropic tracked more than 150,000 exchanges from DeepSeek that seemed aimed at improving foundational logic and alignment, specifically around censor-ship safe alternatives to policy-sensitive queries.\n\nMoonshot AI had more than 3.4 million exchanges targeting agentic reasoning and tool use, coding and data analysis, computer-use agent development, and computer vision. Last month, the firmreleaseda new open source model Kimi K2.5 and a coding agent.\n\nMiniMax’s 13 million exchanges targeted agentic coding and tool use and orchestration. Anthropic said it was able to observe MiniMax in action as it redirected nearly half its traffic to siphon capabilities from the latest Claude model when it was launched.\n\nAnthropic says it will continue to invest in defenses that make distillation attacks harder to execute and easier to identify, but is calling on “a coordinated response across the AI industry, cloud providers, and policymakers.”\n\nThe distillation attacks come at a time whenAmerican chip exportsto China are still hotly debated. Last month, the Trump administration formally allowed U.S. companies like Nvidia toexport advanced AI chips(like the H200) to China. Critics have argued that this loosening of export controls increases China’s AI computing capacity at a critical time in the global race for AI dominance.\n\nAnthropic says that the scale of extraction DeepSeek, MiniMax, and Moonshot performed “requires access to advanced chips.”\n\n“Distillation attacks therefore reinforce the rationale for export controls: restricted chip access limits both direct model training and the scale of illicit distillation,” per Anthropic’s blog.\n\nDmitri Alperovitch, chairman of the Silverado Policy Accelerator think-tank and co-founder of CrowdStrike, told TechCrunch he’s not surprised to see these attacks.\n\n“It’s been clear for a while now that part of the reason for the rapid progress of Chinese AI models has been theft via distillation of US frontier models. Now we know this for a fact,” Alperovitch said. “This should give us even more compelling reasons to refuse to sell any AI chips to any of these [companies],which would only advantage them further.”\n\nAnthropic also said distillation doesn’t only threaten to undercut American AI dominance, but could also create national security risks.\n\n“Anthropic and other U.S. companies build systems that prevent state and non-state actors from using AI to, for example, develop bioweapons or carry out malicious cyber activities,” reads Anthropic’s blog post. “Models built through illicit distillation are unlikely to retain those safeguards, meaning that dangerous capabilities can proliferate with many protections stripped out entirely.”\n\nAnthropic pointed to authoritarian governments deploying frontier AI for things like “offensive cyber operations, disinformation campaigns, and mass surveillance,” a risk that is multiplied if those models are open-sourced.\n\nTechCrunch has reached out to DeepSeek, MiniMax, and Moonshot for comment.",
      "excerpt": "Anthropic isaccusingthree Chinese AI companies of setting up more than 24,000 fake accounts with its Claude AI model to improve their own models.\n\nThe labs —DeepSeek,Moonshot AI, andMiniMax— allegedly generated more than 16 million exchanges with Claude through those accounts using a technique calle",
      "tags": [
        "Apple",
        "Amazon",
        "Cloud Computing",
        "EVs",
        "Google"
      ]
    },
    {
      "title": "With AI, investor loyalty is (almost) dead: at least a dozen OpenAI VCs now also back Anthropic",
      "link": "https://techcrunch.com/2026/02/23/with-ai-investor-loyalty-is-almost-dead-at-least-a-dozen-openai-vcs-now-also-back-anthropic/",
      "author": "Julie Bort",
      "date": "2026-02-23T13:46:41-08:00",
      "image": "https://techcrunch.com/wp-content/uploads/2019/06/GettyImages-516286525.jpg?resize=1200,1200",
      "category": "Venture",
      "content": "With OpenAI onthe verge of finalizing a new $100 billion round, and Anthropic just closing its own monster$30 billion raise, one thing is clear: the concept of investor “loyalty” is only hanging on by a thread.\n\nAt least a dozen direct investors in OpenAI wereannouncedas backers in Anthropic’s $30 billion raise earlier this month, including Founders Fund, Iconiq, Insight Partners, and Sequoia Capital.\n\nSome dual investments are understandable if they come from the hedge fund or asset manager worlds, where their focus is still largely investing in public stocks (competitors or not). These include D1, Fidelity, and TPG.\n\nOne of these was a bit shocking. Affiliated funds of BlackRock joined in Anthropic’s $30 billion raise even though BlackRock’s senior managing director and board memberAdebayo Ogunlesiis also on OpenAI’s board of directors.\n\nIn that world, it’s true that if various BlackRock funds get a chance to own OpenAI stock, they are likely to take it, never mind the personal association of a member of their senior leadership. (BlackRock runs every type of fund, including mutuals, closed-ends, and ETFs).  And we all know thehistory of OpenAI and Microsoft’s relationshipand why Microsoft is hedging its bets. Ditto for Nvidia.\n\nBut venture capital funds have — until now — operated differently.\n\nVCs market themselves as “founder friendly” and “helpful,” the idea being that when a VC firm buys a chunk of a startup’s company, the investor will help that startup be successful, particularly against its major rivals. If you are an owner of both OpenAI and Anthropic, who does your loyalty belong to, besides your own investors?\n\nAdditionally, startups are private companies. They typically share confidential information with their direct investors on their business status — data that isn’t disclosed publicly the way it is with public companies. In many cases, the VCs also take board seats, which carries another level of fiduciary responsibility to their portfolio companies.\n\nWhat makes this particular case even more interesting is that Sam Altman comes from the world of venture capital, as a former president of Y Combinator. He knows the drill. In 2024, he reportedly gave his investorsa list of OpenAI’s rivalsthat he didn’t want them to back. It largely included companies launched by folks who left OpenAI, including Anthropic, xAI, and Safe Superintelligence.\n\nAltman later denied that he told OpenAI investors they would be barred from future rounds if they backed his list of perceived rivals. Altman did admit that he said if they “made non-passive investments,” they would no longer receive OpenAI’s confidential business information, according todocuments in the lawsuitbetween Elon Musk and OpenAI,Business Insider reported.\n\nAI is also breaking the mold because of the record-breaking amounts of money that the largest AI labs are raising as they experience never-before-seen growth (and never-before-seen data center needs). At some point, when the hat is being passed around, the needs are so great and the possibilities of returns are so large, who can be expected to say no?\n\nIt turns out that not all venture investors have yet slid down the slippery slope. Andreessen Horowitz backs OpenAI but not (yet) Anthropic. Menlo Ventures backs Anthropic but not (yet) OpenAI, for instance.\n\nIn fact, in our admittedly not exhaustive research, we found a dozen investors that appear to only have direct investments in one of these companies, not both.\n\nOthers include Bessemer Venture Partners, General Catalyst, and Greenoaks. (Note: we originally asked Claude to give us the list of dual investors. It got almost as many entries wrong as it got right, so all this for a very cool tech whose work sometimes remains less trustworthy than an intern’s.)\n\nStill, as we previously reported, the fact that this longstanding rule has been tossed by some of the most respected firms  in the Valley,like Sequoia, is notable. One investor we reached out to, simply shrugged and said that as long as the firm doesn’t have a board seat, no one sees the harm in it anymore.\n\nStill, conflict-of-interest policies should now become another thing that founders ask about before signing that term sheet, no matter who it’s from.",
      "excerpt": "With OpenAI onthe verge of finalizing a new $100 billion round, and Anthropic just closing its own monster$30 billion raise, one thing is clear: the concept of investor “loyalty” is only hanging on by a thread.\n\nAt least a dozen direct investors in OpenAI wereannouncedas backers in Anthropic’s $30 b",
      "tags": [
        "Apple",
        "Amazon",
        "Cloud Computing",
        "EVs",
        "Google"
      ]
    },
    {
      "title": "Ex-Apple team launches Acme Weather, a new take on weather forecasting",
      "link": "https://techcrunch.com/2026/02/23/ex-apple-team-launches-acme-weather-a-new-take-on-weather-forecasting/",
      "author": "Sarah Perez",
      "date": "2026-02-23T12:35:06-08:00",
      "image": "https://techcrunch.com/wp-content/uploads/2026/02/rainbow-GettyImages-104637612.jpg?resize=1200,799",
      "category": "Apps",
      "content": "The creators of Dark Sky, whosold their popular weather appto Apple in March 2020, are back with a new take on weather forecasting. The team recently announced the launch of their new app,Acme Weather, which they claim offers a better and more reliable forecast than the one they had at Dark Sky. The app will also offer a range of unique weather notifications, including fun ones like alerts about rainbows and beautiful sunsets.\n\nUnlike typical weather apps, Acme Weather’s forecast is supplemented with a range of alternate predictions for better accuracy.\n\nDark Sky co-founder Adam Grossman explains in an introductoryblog postthat the app’s homegrown forecasts will leveragedifferentnumerical weather prediction models, satellite data, ground station observations, and radar data, making its forecast fairly reliable.\n\nHowever, the app will also feature additional forecast lines that show the other possible outcomes as gray lines on its graphs.\n\n“Forecasts are often wrong — it’s the weather, right? It’s one of the hardest things to predict,” Grossman told TechCrunch via a telephone interview. “And our biggest pet peeve with a lot of weather apps is you just get their best guess, and you don’t know how certain they are.”\n\nHaving an understanding of the alternatives helps people plan for big events, he noted.\n\n“I find it most useful for winter storms, where, maybe the storm starts out in the morning, and you’re going to get snow, but maybe there’s also a possibility it holds out a little bit later — to the afternoon — in which case it’s rain,” Gross explained. “Being able to just see that right there on the timeline just gives you this intuitive sense of whether, do all the models agree, and you’re getting snow? Or do half of them say snow and half of them say rain?”,” he says.”\n\nThis type of weather data could make for a valuable product, not just for consumers, but for other developers, too.\n\nAt Dark Sky, the team had offered its weather API to developers for a fee. After being acquired by Apple, the team worked on creatingWeatherKit, the developer toolkit that provides access to Apple’s weather data on a subscription basis. Grossman said the team hasn’t yet decided if a developer API will be a part of Acme Weather’s offering.\n\nInstead, Acme Weather is a $25 per year consumer app, with a two-week free trial. This helps to cover the costs involved with pulling in thedifferent weather models and resources, which can be expensive.\n\n“Most of our time has been spent on building our own forecast — our own data provider, in a way. And this lets us do things like build multiple forecasts…[and] create any map we want, rather than having to rely on a third-party map provider,” Grossman noted.\n\nAt launch, the app offers a range of maps, like radar, lightning, rain and snow totals, as well as wind, temperature, humidity, cloud cover, and hurricane tracks.\n\nAnother feature, Community Reports, lets users share information about their current conditions to improve the app’s real-time weather reporting.\n\nWhile Dark Sky had become a favorite weather app because of its uncanny ability to predict when it would begin raining in your location, Acme Weather aims to improve on this and even have some fun.\n\nThe app includes built-in notifications for typical things, like rain, nearby lightning, community reports, government-issued severe weather alerts, and more. It’s also going to experiment with alerts like rainbow predictions or those to identify when you might see a beautiful sunset.\n\nThese will be available in a special “Acme Labs” section of the app, and Grossman said they’ll be conservative with their predictions, given the difficulty.\n\nUsers will also be able to customize their notifications to focus on weather events they care about, like winds or UV index, or the possibility of rain over the next 24 hours.\n\nBeing able to try new ideas is part of what drew the team back to building an indie app, Grossman noted.\n\n“I absolutely love Apple…but as a big company, it’s difficult to try weird, new, experimental ideals. If you have a billion users, mistakes are costly,” he tells TechCrunch. “There’s long software development cycles, there’s a lot of stakeholders, this idea of being able to try a bunch of things, I think, is interesting.”\n\nAcme Weather is currently available on iOS. An Android version is planned.\n\nThe team is bootstrapped and includes co-foundersJosh ReyesandDan Abrutyn, also previously of Dark Sky. The small workforce includes both former Dark Sky team members and new hires.",
      "excerpt": "The creators of Dark Sky, whosold their popular weather appto Apple in March 2020, are back with a new take on weather forecasting. The team recently announced the launch of their new app,Acme Weather, which they claim offers a better and more reliable forecast than the one they had at Dark Sky. The",
      "tags": [
        "Apple",
        "Amazon",
        "Cloud Computing",
        "EVs",
        "Google"
      ]
    },
    {
      "title": "OpenAI calls in the consultants for its enterprise push",
      "link": "https://techcrunch.com/2026/02/23/openai-calls-in-the-consultants-for-its-enterprise-push/",
      "author": "Rebecca Szkutak",
      "date": "2026-02-23T10:11:08-08:00",
      "image": "https://techcrunch.com/wp-content/uploads/2025/04/GettyImages-2206295463.jpg?resize=1200,800",
      "category": "Enterprise",
      "content": "OpenAI is beefing up partnerships with four major consulting giants as the AI company looks to grow its enterprise business in 2026.\n\nOpenAI announced on Monday the“Frontier Alliances,”a signal that the AI lab is willing to try different approaches to get enterprises to meaningfully adopt its technology. The alliance includes multi-year partnerships between OpenAI and four major consulting firms, Boston Consulting Group (BCG), McKinsey, Accenture, and Capgemini, to sell its enterprise products.\n\nOpenAI’s Forward Deployed Engineering team will work with the consulting giants to help them implement OpenAI’s enterprise-focused technologies like OpenAI Frontier into customers’ tech stacks.\n\nThe companylaunched OpenAI Frontier in early February. The no-code open software allows users to build, deploy, and manage AI agents both built on OpenAI’s AI models and beyond.\n\nOpenAI argues in its latest announcement that consultants are the right avenue to get enterprises on board.\n\n“AI alone does not drive transformation. It must be linked to strategy, built into redesigned processes, and adopted at scale with aligned incentives and culture to deliver sustained outcomes,” BCG CEO Christoph Schweizer said in OpenAI’s blog post. “Our expanded partnership combines OpenAI’s Frontier platform with BCG’s deep industry, functional, and tech expertise and BCG X’s build-and-scale capabilities to drive measurable impact with safeguards from day one.”\n\nThus far,enterprise adoption of AI has been relatively slowas these companies struggle to find a meaningful return on investment from their AI pursuits.\n\nOpenAI’s alliance strategy makes sense and goes beyond just pitching enterprises on attaching AI to their existing workflows. Instead, this effort focuses on consultants persuading companies to change their strategies and workflows to fold in OpenAI’s tools where it makes sense.\n\nIt’s worth noting the OpenAI rival Anthropic has inked deals with consulting giants, includingDeloitteandAccenturein recent months too.\n\nCompany CFO Sarah Friar wrote in a blog post in January that enterprise is abig area of focus for OpenAIin 2026. OpenAI has also inked sizable enterprise AI deals withSnowflakeandServiceNowso far this year, in addition to naming Barret Zoph to lead the company’s enterprise sales effort in January.",
      "excerpt": "OpenAI is beefing up partnerships with four major consulting giants as the AI company looks to grow its enterprise business in 2026.\n\nOpenAI announced on Monday the“Frontier Alliances,”a signal that the AI lab is willing to try different approaches to get enterprises to meaningfully adopt its techno",
      "tags": [
        "Apple",
        "Amazon",
        "Cloud Computing",
        "EVs",
        "Google"
      ]
    },
    {
      "title": "Guide Labs debuts a new kind of interpretable LLM",
      "link": "https://techcrunch.com/2026/02/23/guide-labs-debuts-a-new-kind-of-interpretable-llm/",
      "author": "Tim Fernholz",
      "date": "2026-02-23T09:53:28-08:00",
      "image": "https://techcrunch.com/wp-content/uploads/2026/02/Screenshot-2026-02-23-at-9.31.05-AM.png?resize=1200,639",
      "category": "AI",
      "content": "The challenge of wrangling a deep learning model is often understanding why it does what it does: Whether it’s xAI’s repeated struggle sessions to fine-tune Grok’s odd politics, ChatGPT’s struggles with sycophancy, or run-of-the-mill hallucinations, plumbing through a neural network with billions of parameters isn’t easy.\n\nGuide Labs, a San Francisco startup founded by CEO Julius Adebayo and chief science officer Aya Abdelsalam Ismail, is offering an answer to that problem today. On Monday, the company open sourced an 8-billion-parameter LLM,Steerling-8B, trained with a new architecture designed to make its actions easily interpretable: Every token produced by the model can be traced back to its origins in the LLM’s training data.\n\nThat can be as simple as determining the reference materials for facts cited by the model, or as complex as understanding the model’s understanding of humor or gender.\n\n“If I have a trillion ways to encode gender, and I encode it in 1 billion of the 1 trillion things that I have, you have to make sure you find all those 1 billion things that I’ve encoded, and then you have to be able to reliably turn that on, turn them off,” Adebayo told TechCrunch. “You can do it with current models, but it’s very fragile … It’s sort of one of the holy grail questions.”\n\nAdebayo began this work while earning his PhD at MIT, co-authoring a widely cited2018 paperthat showed existing methods of understanding deep learning models were not reliable. That work ultimately led to the creation of a new way of building LLMs: Developers insert a concept layer in the model that buckets data into traceable categories. This requires more up-front data annotation, but by using other AI models to help, they were able to train this model as their largest proof of concept yet.\n\n“The kind of interpretability people do is … neuroscience on a model, and we flip that,” Adebayo said. “What we do is actually engineer the model from the ground up so that you don’t need to do neuroscience.”\n\nOne concern with this approach is that it might eliminate some of the emergent behaviors that make LLMs so intriguing: Their ability to generalize in new ways about things they haven’t been trained on yet. Adebayo says that still happens in his company’s model: His team tracks what they call “discovered concepts” that the model discovered on its own, like quantum computing.\n\nAdebayo argues this interpretable architecture will be something everyone needs. For consumer-facing LLMs, these techniques should allow model builders to do things like block the use of copyrighted materials, or better control outputs around subjects like violence or drug abuse. Regulated industries will require more controllable LLMs — for example, in finance — where a model evaluating loan applicants needs to consider things like financial records but not race. There’s also a need for interpretability in scientific work, another area where Guide Labs has developed technology. Protein folding has been a big success for deep learning models, but scientists need more insight into why their software figured out promising combinations.\n\n“This model demonstrates that training interpretable models is no longer a sort of science; it’s now an engineering problem,” Adebayo said. “We figured out the science and we can scale them, and there is no reason why this kind of model wouldn’t match the performance of the frontier level models,” which have many more parameters.\n\nGuide Labs says that Steerling-8B can achieve 90% of the capability of existing models, but uses less training data, thanks to its novel architecture. The next step for the company, which emerged from Y Combinator and raised a $9 million seed round from Initialized Capital in November 2024, is to build a larger model and begin offering API and agentic access to users.\n\n“The way we’re currently training models is super primitive, and so democratizing inherent interpretability is actually going to be a long-term good thing for our role within the human race,” Adebayo told TechCrunch. “As we’re going after these models that are going to be super intelligent, you don’t want something to be making decisions on your behalf that’s sort of mysterious to you.”",
      "excerpt": "The challenge of wrangling a deep learning model is often understanding why it does what it does: Whether it’s xAI’s repeated struggle sessions to fine-tune Grok’s odd politics, ChatGPT’s struggles with sycophancy, or run-of-the-mill hallucinations, plumbing through a neural network with billions of",
      "tags": [
        "Apple",
        "Amazon",
        "Cloud Computing",
        "EVs",
        "Google"
      ]
    },
    {
      "title": "Particle’s AI news app listens to podcasts for interesting clips so you you don’t have to",
      "link": "https://techcrunch.com/2026/02/23/particles-ai-news-app-listens-to-podcasts-for-interesting-clips-so-you-you-dont-have-to/",
      "author": "Sarah Perez",
      "date": "2026-02-23T08:55:40-08:00",
      "image": "https://techcrunch.com/wp-content/uploads/2026/02/share_6305813549552173171.png?resize=540,1200",
      "category": "Apps",
      "content": "An AI news app calledParticle, fromformer Twitter engineers, can now keep up with news breaking on podcasts as well as news published on the web.\n\nJust ahead of its recent Android release, Particle has introduced a feature called Podcast Clips, which finds the most interesting and relevant moments across many different types of podcasts, and then includes those clips alongside the related news stories in its feed.\n\nSo instead of listening to a lengthy podcast just to catch the 45 seconds of interesting comments, you can play back the clip as you’re reading the news on Particle. You also have the option of reading the transcript of the clip instead, as the words are highlighted as they’re spoken.\n\n“We’ve done that basically for any news story — if there is a podcast that is talking about it, or relevant at all, we’ve got all those clips,” Particle CEOSara Beykpour, previously the Senior Director of Product Management at Twitter, told TechCrunch. “It’s a really cool way, when you’re reading a story or learning about a story, to get a breath of what are people saying about this? What’s the commentary?”\n\nThe addition acknowledges a shift in the news ecosystem that’s been underway for years. Not only are more peoplegetting their news from podcastsand trusting them as reliable sources, but the medium is alsobecoming a destinationfor breaking news and major announcements from public figures.\n\nTech CEOs, in particular, are now seeking out friendly podcast hosts to air their talking points instead of trying to work with traditional media, asBloomberg reportedin 2024.\n\nThat makes paying attention to podcasts even more critical if you want to keep up with news.\n\nBeykpour says Particle usesembedding modelsto understand when podcasts relate to a given news story. These models are provided by the same companies that provide LLM models, but they’re not generative AI technologies, she explains.\n\n“We use vector embeddings to understand that these different parts of the podcasts are related to these different stories,” Beykpour notes. “A single podcast might cover 10 or 20 stories, so we use AI to understand that. We also use AI to do some of the logic around clipping, and understanding when to start a clip and end a clip.”\n\nThe company leverages technology from ElevenLabs for transcription. However, some of the technology that identifies where exactly to clip the audio is part of Particle’s secret sauce.\n\nThe idea to tap into podcasts to better understand the commentary around news is also something newsrooms are taking a closer look at these days. AsNieman Lab reportedthis month, The New York Times has been using a custom AI tool that employs LLMs to transcribe and summarize new episodes of dozens of right-wing and more conservative podcasts to better understand what influencers on that side are saying about the news.\n\nParticle’s Podcast Clips feature isn’t tied to only news stories. Because the app already understands different entities — like people, places, or things — you can go to the page for a notable figure, such as OpenAI CEO Sam Altman, to see all of his appearances on podcasts arranged as a feed.\n\nParticle has been busy building other features as well. The company has made its first attempt at monetization with Particle+, an optional $2.99/month subscription (or $29.99/year) that lets you access premium features. These include the ability to use natural language to have the news summarized in a style you prefer; pick from different voices when using the personalized audio feed; “Listen to the News”; unlimited crossword puzzles; support for private questions with its AI chatbot; and more.\n\nThe Android release also brings a couple of other notable changes. The browse tab now includes timely stories, like the 2026 Winter Olympics, in addition to typical sections like politics, tech, or entertainment. Plus, when you tap on an entity, you’ll see a new page with the definition, stories, articles, related entities, and related topics.\n\nParticle isn’t sharing data about user activity or conversion rates, but Beykpour did point to the app’s international audience, pre-Android. On a weekly basis, 55% of Particle’s users are outside the U.S., with India (15%) its biggest market after the U.S.",
      "excerpt": "An AI news app calledParticle, fromformer Twitter engineers, can now keep up with news breaking on podcasts as well as news published on the web.\n\nJust ahead of its recent Android release, Particle has introduced a feature called Podcast Clips, which finds the most interesting and relevant moments a",
      "tags": [
        "Apple",
        "Amazon",
        "Cloud Computing",
        "EVs",
        "Google"
      ]
    },
    {
      "title": "6 days left to lock in the lowest TechCrunch Disrupt 2026 rates",
      "link": "https://techcrunch.com/2026/02/22/6-days-left-to-lock-in-the-lowest-techcrunch-disrupt-2026-rates/",
      "author": "TechCrunch Events",
      "date": "2026-02-22T07:00:00-08:00",
      "image": "https://techcrunch.com/wp-content/uploads/2025/10/Disrupt-2025-day-3.jpg?resize=1200,800",
      "category": "Startups",
      "content": "Super Early Bird pricing forTechCrunch Disrupt 2026ends February 27 at 11:59 p.m. PT. That means you have just 6 days left to secure the lowest ticket prices of the year.\n\nIf Disrupt has been on your must-attend list, this is your moment. Save up to $680 on your individual pass or secure up to 30% off with community passes before prices increase.Register here.\n\nFrom October 13-15 at San Francisco’s Moscone West, TechCrunch will bring together 10,000 founders, investors, operators, and innovators for three focused days built around launching, scaling, and shaping what’s next in tech.\n\nDisrupt is where you get:\n\nYou’ll see300+ exhibiting startupsdebut tomorrow’s breakthroughs, experience the high-stakesStartup Battlefield 200pitch competition — where one standout company wins a $100,000 equity-free prize — and take part in curated networking designed to drive real outcomes.\n\nYou’ll also hear insights from some of the most influential voices in tech, including WordPress co-founderMatt Mullenweg, General Motors CEOMary Barra, and legendary VCVinod Khosla. Keep an eye on theevent pagefor the agenda drop.\n\nSix days remain to secure the lowest rate of the year. Lock it in before February 27 at 11:59 p.m. PT.Register here.",
      "excerpt": "Super Early Bird pricing forTechCrunch Disrupt 2026ends February 27 at 11:59 p.m. PT. That means you have just 6 days left to secure the lowest ticket prices of the year.\n\nIf Disrupt has been on your must-attend list, this is your moment. Save up to $680 on your individual pass or secure up to 30% o",
      "tags": [
        "Apple",
        "Amazon",
        "Cloud Computing",
        "EVs",
        "Google"
      ]
    },
    {
      "title": "Google’s Cloud AI lead on the three frontiers of model capability",
      "link": "https://techcrunch.com/2026/02/23/googles-cloud-ai-lead-on-the-three-frontiers-of-model-capability/",
      "author": "Russell Brandom",
      "date": "2026-02-23T11:18:42-08:00",
      "image": "https://techcrunch.com/wp-content/uploads/2026/02/google-logo.jpg?resize=1200,800",
      "category": "AI",
      "content": "As a product VP at Google Cloud, Michael Gerstenhaber works mostly on Vertex AI, the company’s unified platform for deploying enterprise AI. It gives him a high-level view of how companies are actually using AI models, and what still needs to be done to unleash the potential of agentic AI.\n\nWhen I spoke with Michael, I was particularly struck by one idea I hadn’t heard before. As he put it, AI models are pushing against three frontiers at once: raw intelligence, response time, and a third quality that has less to do with raw capability than with cost — whether a model can be deployed cheaply enough to run at massive, unpredictable scale. It’s a new way of thinking about model capabilities, and a particularly valuable one for anyone trying to push frontier models in a new direction.\n\nThis interview has been edited for length and clarity.\n\nWhy don’t you start by walking us through your experience in AI so far, and what you do at Google?\n\nI’ve been in AI for about two years now. I was at Anthropic for a year and a half, I’ve been at Google almost half a year now. I run Vertex AI, Google’s developer platform. Most of our customers are engineers building their own applications. They want access to agentic patterns. They want access to an agentic platform. They want access to the inference of the smartest models in the world. I provide them that, but I don’t provide the applications themselves. That’s for Shopify, Thomson Reuters, and our various customers to provide in their own domains.\n\nWhat drew you to Google?\n\nGoogle is I think unique in the world in that we have everything from the interface to the infrastructure layer. We can build data centers. We can buy electricity and build power plants. We have our own chips. We have our own model. We have the inference layer that we control. We have the agentic layer we control. We have APIs for memory, for interleaved code writing. We have agent engine on top of that that ensures compliance and governance. And then we even have the chat interface with Gemini enterprise and Gemini chat for consumers, right? So part of the reason I came here is because I saw Google as uniquely vertically integrated, and that being a strength for us.\n\nIt’s odd because, even with all the differences between companies, it feels like all three of the big labs are reallyclose in capabilities. Is it just a race for more intelligence, or is it more complicated than that?\n\nI see three boundaries. Models like Gemini Pro are tuned for raw intelligence. Think about writing code. You just want the best code you can get, doesn’t matter if it takes 45 minutes, because I have to maintain it, I have to put it in production. I just want the best.\n\nThen there’s this other boundary with latency. If I’m doing customer support and I need to know how to apply a policy, you need intelligence to apply that policy. Are you allowed to transact a return? Can I upgrade my seat on an airplane? But it doesn’t matter how right you are if it took 45 minutes to get the answer. So for those cases, you want the most intelligent product within that latency budget, because more intelligence no longer matters once that person gets bored and hangs up the phone.\n\nAnd then there’s this last bucket, where somebody like Reddit or Meta wants to moderate the entire internet. They have large budgets, but they can’t take an enterprise risk on something if they don’t know how it scales. They don’t know how many poisonous posts there will be today or tomorrow. So they have to restrict their budget to a model at the highest intelligence they can afford, but in a scalable way to an infinite number of subjects. And for that, cost becomes very, very important.\n\nOne of the things I’ve been puzzling about is why agentic systems are taking so long to catch on. It feels like the models are there and I’ve seen incredible demos, but we’re not seeing the kind of major changes I would have expected a year ago. What do you think is holding it back?\n\nThis technology is basically two years old, and there’s still a lot of missing infrastructure. We don’t have patterns for auditing what the agents are doing. We don’t have patterns for authorization of data to an agent. There are these patterns that are going to require work to put into production. And production is always a trailing indicator of what the technology is capable of. So two years isn’t long enough to see what the intelligence supports in production, and that’s where people are struggling.\n\nI think it’s moved uniquely quickly in software engineering because it fits nicely in the software development lifecycle. We have a dev environment in which it’s safe to break things, and then we promote from the dev environment to the test environment. The process of writing code at Google requires two people to audit that code and both affirm that it’s good enough to put Google’s brand behind and give to our customers. So we have a lot of those human-in-the-loop processes that make the implementation exceptionally low-risk. But we need to produce those patterns in other places and for other professions.",
      "excerpt": "As a product VP at Google Cloud, Michael Gerstenhaber works mostly on Vertex AI, the company’s unified platform for deploying enterprise AI. It gives him a high-level view of how companies are actually using AI models, and what still needs to be done to unleash the potential of agentic AI.\n\nWhen I s",
      "tags": [
        "Apple",
        "Amazon",
        "Cloud Computing",
        "EVs",
        "Google"
      ]
    },
    {
      "title": "Americans are destroying Flock surveillance cameras",
      "link": "https://techcrunch.com/2026/02/23/americans-are-destroying-flock-surveillance-cameras/",
      "author": "Zack Whittaker",
      "date": "2026-02-23T10:49:49-08:00",
      "image": "https://techcrunch.com/wp-content/uploads/2026/02/flock-camera-2259453437.jpg?resize=1200,862",
      "category": "Security",
      "content": "Brian Merchant, writing forBlood in the Machine, reports that people across the United States are dismantling and destroying Flock surveillance cameras, amid rising public anger that the license plate readers aid U.S. immigration authorities and deportations.\n\nFlock is the Atlanta-based surveillance startupvalued at $7.5 billion a year agoand a maker of license plate readers. It has faced criticism for allowing federal authorities access to its massive network of nationwide license plate readers and databases at a time when U.S. Immigration and Customs Enforcement are increasinglyrelying on datato raid communities as part of the Trump administration’s immigration crackdown.\n\nFlock cameras allow authorities to track where people go and when by taking photos of their license plates from thousands of cameras located across the United States. Flock claims it doesn’t share data with ICE directly, but reports show that local police have shared their own access to Flock cameras and its databases with federal authorities.\n\nWhile some communities are calling on their cities toend their contracts with Flock, others are taking matters into their own hands.\n\nMerchant reports instances of broken and smashed Flock cameras in La Mesa, California, just weeks after the city council approved the continuation of Flock cameras deployed in the city, despite a clear majority of attendees favoring their shutdown. Alocal reportcited strong opposition to the surveillance technology, with residents raising privacy concerns.\n\nOther cases of vandalism have stretched from California and Connecticut, to Illinois and Virginia. InOregon, six license plate scanning cameras on poles were cut down and at least one spray painted. A note left at the base of the severed poles said, “Hahaha get wrecked ya surveilling fucks,”reports Merchant.\n\nAccording toDeFlock, a project aimed at mapping license plate readers, there are close to 80,000 cameras across the United States. Dozens of cities have so far rejected the use of Flock’s cameras, and some police departments havesince blockedfederal authorities from using their resources.\n\nA Flock spokesperson did not say, when reached by TechCrunch, if the company keeps track of how how many cameras have been destroyed since being deployed.",
      "excerpt": "Brian Merchant, writing forBlood in the Machine, reports that people across the United States are dismantling and destroying Flock surveillance cameras, amid rising public anger that the license plate readers aid U.S. immigration authorities and deportations.\n\nFlock is the Atlanta-based surveillance",
      "tags": [
        "Apple",
        "Amazon",
        "Cloud Computing",
        "EVs",
        "Google"
      ]
    }
  ]
}