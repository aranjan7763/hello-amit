{
  "last_updated": "2026-03-01T11:23:45.787398+00:00",
  "articles": [
    {
      "title": "The trap Anthropic built for itself",
      "link": "https://techcrunch.com/2026/02/28/the-trap-anthropic-built-for-itself/",
      "author": "Connie Loizos",
      "date": "2026-02-28T16:08:58-08:00",
      "image": "https://techcrunch.com/wp-content/uploads/2026/02/GettyImages-2261854833.jpg?resize=1200,800",
      "category": "AI",
      "content": "Friday afternoon, just as this interview was getting underway, a news alert flashed across my computer screen: the Trump administration was severing ties with Anthropic, the San Francisco AI company founded in 2021 by Dario Amodei. Defense Secretary Pete Hegseth soon after invoked anational security lawto blacklist the company from doing business with the Pentagon after Amodei refused to allow Anthropic’s tech to be used for mass surveillance of U.S. citizens or for autonomous armed drones that could select and kill targets without human input.\n\nIt was a jaw-dropping sequence of events. Anthropic stands to lose a contract worth up to $200 million and could be barred from working with other defense contractors after President Trump posted on Truth Social directing every federal agency to “immediately cease all use of Anthropic technology.” (Anthropic has since said it willchallenge the Pentagon in court.)\n\nMax Tegmark has spent the better part of a decade warning that the race to build ever-more-powerful AI systems is outpacing the world’s ability to govern them. The MIT physicist founded theFuture of Life Institutein 2014 and in 2023 helped organize anopen letter— ultimately signed by more than 33,000 people, including Elon Musk — calling for a pause in advanced AI development.\n\nHis view of the Anthropic crisis is unsparing: the company, like its rivals, has sown the seeds of its own predicament. Tegmark’s argument doesn’t begin with the Pentagon but with a decision made years earlier — a choice, shared across the industry, to resist regulation. Anthropic, OpenAI, Google DeepMind and others have long promised to govern themselves responsibly. Anthropic this week even dropped thecentral tenet of its own safety pledge— its promise not to release increasingly powerful AI systems until the company was confident they wouldn’t cause harm.\n\nNow, in the absence of rules, there’s not a lot to protect these players, says Tegmark. Here’s more from that interview, edited for length and clarity. You can hear the full conversation this coming week on TechCrunch’sStrictlyVC Downloadpodcast.\n\nWhen you saw this news just now about Anthropic, what was your first reaction?\n\nThe road to hell is paved with good intentions. It’s so interesting to think back a decade ago, when people were so excited about how we were going to make artificial intelligence to cure cancer, to grow the prosperity in America and make America strong. And here we are now where the U.S. government is pissed off at this company for not wanting AI to be used for domestic mass surveillance of Americans, and also not wanting to have killer robots that can autonomously — without any human input at all — decide who gets killed.\n\nAnthropic has staked its entire identity on being a safety-first AI company, and yet it was collaborating with defense and intelligence agencies [dating back to at least 2024]. Do you think that’s at all contradictory?\n\nIt is contradictory. If I can give a little cynical take on this — yes, Anthropic has been very good at marketing themselves as all about safety. But if you actually look at the facts rather than the claims, what you see is that Anthropic, OpenAI, Google DeepMind and xAI have all talked a lot about how they care about safety. None of them has come out supporting binding safety regulation the way we have in other industries. And all four of these companies have now broken their own promises. First we had Google — this big slogan, ‘Don’t be evil.’ Then they dropped that. Then they dropped another longer commitment that basically said they promised not to do harm with AI. They dropped that so they could sell AI for surveillance and weapons. OpenAI just dropped the word safety from their mission statement. xAI shut down their whole safety team. And now Anthropic, earlier in the week, dropped their most important safety commitment — the promise not to release powerful AI systems until they were sure they weren’t going to cause harm.\n\nHow did companies that made such prominent safety commitments end up in this position?\n\nAll of these companies, especially OpenAI and Google DeepMind but to some extent also Anthropic, have persistently lobbied against regulation of AI, saying, ‘Just trust us, we’re going to regulate ourselves.’ And they’ve successfully lobbied. So we right now have less regulation on AI systems in America than on sandwiches. You know, if you want to open a sandwich shop and the health inspector finds 15 rats in the kitchen, he won’t let you sell any sandwiches until you fix it. But if you say, ‘Don’t worry, I’m not going to sell sandwiches, I’m going to sell AI girlfriends for 11-year-olds, and they’ve been linked to suicides in the past, and then I’m going to release something called superintelligence which might overthrow the U.S. government, but I have a good feeling about mine’ — the inspector has to say, ‘Fine, go ahead, just don’t sell sandwiches.’\n\nThere’s food safety regulation and no AI regulation.And this, I feel, all of these companies really share the blame for. Because if they had taken all these promises that they made back in the day for how they were going to be so safe and goody-goody, and gotten together, and then gone to the government and said, ‘Please take our voluntary commitments and turn them into U.S. law that binds even our most sloppy competitors’ — this would have happened. Instead, we’re in a complete regulatory vacuum. And we know what happens when there’s a complete corporate amnesty: you getthalidomide, you get tobacco companies pushing cigarettes on kids, you get asbestos causing lung cancer. So it’s sort of ironic that their own resistance to having laws saying what’s okay and not okay to do with AI is now coming back and biting them.\n\nThere is no law right now against building AI to kill Americans, so the government can just suddenly ask for it. If the companies themselves had earlier come out and said, ‘We want this law,’ they wouldn’t be in this pickle. They really shot themselves in the foot.\n\nThe companies’ counter-argument is always the race with China — if American companies don’t do such and such, Beijing will. Does that argument hold?\n\nLet’s analyze that. The most common talking point from the lobbyists for the AI companies — they’re now better funded and more numerous than the lobbyists from the fossil fuel industry, the pharma industry and the military-industrial complex combined — is that whenever anyone proposes any kind of regulation, they say, ‘But China.’ So let’s look at that. China is in the process of banning AI girlfriends outright. Not just age limits — they’re looking at banningall anthropomorphic AI. Why? Not because they want to please America but because they feel this is screwing up Chinese youth and making China weak. Obviously, it’s making American youth weak, too.\n\nAnd when people say we have to race to build superintelligence so we can win against China — when we don’t actually know how to control superintelligence, so that the default outcome is that humanity loses control of Earth to alien machines — guess what? The Chinese Communist Party really likes control. Who in their right mind thinks that Xi Jinping is going to tolerate some Chinese AI company building something that overthrows the Chinese government? No way. It’s clearly really bad for the American government too if it gets overthrown in a coup by the first American company to build superintelligence. This is a national security threat.\n\nThat’s compelling framing — superintelligence as a national security threat, not an asset. Do you see that view gaining traction in Washington?\n\nI think if people in the national security community listen to Dario Amodei describe his vision — he’s given a famous speech where he says we’ll soon have acountry of geniuses in a data center— they might start thinking: ‘Wait, did Dario just use the word country? Maybe I should put that country of geniuses in a data center on the same threat list I’m keeping tabs on, because that sounds threatening to the U.S. government.’ And I think fairly soon, enough people in the U.S. national security community are going to realize that uncontrollable superintelligence is a threat, not a tool. This is totally analogous to the Cold War. There was a race for dominance — economic and military — against the Soviet Union. We Americans won that one without ever engaging in the second race, which was to see who could put the most nuclear craters in the other superpower. People realized that was just suicide. No one wins. The same logic applies here.\n\nWhat does all of this mean for the pace of AI development more broadly? And how close do you think we are to the systems you’re describing?\n\nSix years ago, almost every expert in AI I knew predicted we were decades away from having AI that could master language and knowledge at human level — maybe 2040, maybe 2050. They were all wrong, because we already have that now. We’ve seen AI progress quite rapidly from high school level to college level to PhD level to university professor level in some areas. Last year, AI won the gold medal at the International Mathematics Olympiad, which is about as difficult as human tasks get. Iwrote a papertogether withYoshua Bengio,Dan Hendrycks, and other top AI researchers just a few months ago giving a rigorous definition of AGI. According to this, GPT-4 was 27% of the way there. GPT-5 was 57% of the way there. So we’re not there yet, but going from 27% to 57% that quickly suggests it might not be that long.\n\nWhen I lectured to my students yesterday at MIT, I told them that even if it takes four years, that means when they graduate, they might not be able to get any jobs anymore. It’s certainly not too soon to start preparing for it.\n\nAnthropic is now blacklisted. I’m curious to see what happens next — will the other AI giants stand with it and say, ‘We won’t do this either?’ Or does someone like xAI raise their hand and say, ‘Anthropic didn’t want that contract, we’ll take it’?[Editor’s note: Hours after the interview, OpenAI announced itsown dealwith the Pentagon.]\n\nLast night, Sam Altman came out and said he stands with Anthropic and has the same red lines. I admire him for the courage of saying that. Google, as of when we started this interview, had said nothing. If they just stay quiet, I think that’s incredibly embarrassing for them as a company, and a lot of their staff will feel the same. We haven’t heard anything from xAI yet either. So it’ll be interesting to see. Basically, there’s this moment where everybody has to show their true colors.\n\nIs there a version of this where the outcome is actually good?\n\nYes, and this is why I’m actually optimistic in a strange way. There’s such an obvious alternative here. If we just start treating AI companies like any other companies — drop the corporate amnesty — they would clearly have to do something like a clinical trial before they released something this powerful, and demonstrate to independent experts that they know how to control it. Then we get a golden age with all the good stuff from AI, without the existential angst. That’s not the path we’re on right now. But it could be.",
      "excerpt": "Friday afternoon, just as this interview was getting underway, a news alert flashed across my computer screen: the Trump administration was severing ties with Anthropic, the San Francisco AI company founded in 2021 by Dario Amodei. Defense Secretary Pete Hegseth soon after invoked anational security",
      "tags": [
        "Apple",
        "Amazon",
        "Cloud Computing",
        "EVs",
        "Google"
      ]
    },
    {
      "title": "OpenAI’s Sam Altman announces Pentagon deal with ‘technical safeguards’",
      "link": "https://techcrunch.com/2026/02/28/openais-sam-altman-announces-pentagon-deal-with-technical-safeguards/",
      "author": "Anthony Ha",
      "date": "2026-02-28T08:17:36-08:00",
      "image": "https://techcrunch.com/wp-content/uploads/2026/02/GettyImages-2236544077.jpg?resize=1200,800",
      "category": "Government & Policy",
      "content": "OpenAI CEO Sam Altman announced late on Friday that his company has reached an agreement allowing the Department of Defense to use its AI models in the department’s classified network.\n\nThis follows a high-profile standoff between the DoD — also known under the Trump administration as the Department of War — and OpenAI’s rival Anthropic. The Pentagonpushed AI companies, including Anthropic, to allow their models to be used for “all lawful purposes,”while Anthropic sought to draw a red line around mass domestic surveillance and fully autonomous weapons.\n\nIna lengthy statement released Thursday, Anthropic CEO Dario Amodei said the company “never raised objections to particular military operations nor attempted to limit use of our technology in anad hocmanner,” but he argued that “in a narrow set of cases, we believe AI can undermine, rather than defend, democratic values.”\n\nMore than 60 OpenAI employees and 300 Google employeessigned an open letter this weekasking their employers to support Anthropic’s position.\n\nAfter Anthropic and the Pentagon failed to reach an agreement, President Donald Trump criticized the “Leftwing nut jobs at Anthropic” ina social media postthat also directed federal agencies to stop using the company’s products after a six-month phase-out period.\n\nInaseparatepost, Secretary of Defense Pete Hegseth claimed Anthropic was trying to “seize veto power over the operational decisions of the United States military.” Hegseth also said he is designating Anthropic as a supply-chain risk: “Effective immediately, no contractor, supplier, or partner that does business with the United States military may conduct any commercial activity with Anthropic.”\n\nOn Friday,Anthropic saidit had “not yet received direct communication from the Department of War or the White House on the status of our negotiations,” but insisted it would “challenge any supply chain risk designation in court.”\n\nSurprisingly, Altmanclaimed in a post on Xthat OpenAI’s new defense contract includes protections addressing the same issues that became a flashpoint for Anthropic.\n\n“Two of our most important safety principles are prohibitions on domestic mass surveillance and human responsibility for the use of force, including for autonomous weapon systems,” Altman said. “The DoW agrees with these principles, reflects them in law and policy, and we put them into our agreement.”\n\nAltman said OpenAI “will build technical safeguards to ensure our models behave as they should, which the DoW also wanted,” and it will deploy engineers with the Pentagon “to help with our models and to ensure their safety.”\n\n“We are asking the DoW to offer these same terms to all AI companies, which in our opinion we think everyone should be willing to accept,” Altman added. “We have expressed our strong desire to see things de-escalate away from legal and governmental actions and towards reasonable agreements.”\n\nFortune’s Sharon Goldman reportsthat Altman told OpenAI employees at an all-hands meeting that the government will allow the company to build its own “safety stack” to prevent misuse and that “if the model refuses to do a task, then the government would not force OpenAI to make it do that task.”\n\nAltman’s post came shortly before news broke that the U.S. and Israeli governmentshave begun bombing Iran, with Trump calling for the overthrow of the Iranian government.",
      "excerpt": "OpenAI CEO Sam Altman announced late on Friday that his company has reached an agreement allowing the Department of Defense to use its AI models in the department’s classified network.\n\nThis follows a high-profile standoff between the DoD — also known under the Trump administration as the Department",
      "tags": [
        "Apple",
        "Amazon",
        "Cloud Computing",
        "EVs",
        "Google"
      ]
    },
    {
      "title": "Xiaomi launches 17 Ultra smartphone, an AirTag clone, and an ultra slim powerbank",
      "link": "https://techcrunch.com/2026/02/28/xiaomi-launches-17-ultra-smartphone-an-airtag-clone-and-an-ultra-slim-powerbank/",
      "author": "Ivan Mehta",
      "date": "2026-02-28T07:09:03-08:00",
      "image": "https://techcrunch.com/wp-content/uploads/2026/02/xiaomi.jpg?resize=1200,600",
      "category": "Hardware",
      "content": "Xiaomi today launched a slew of gadgets ahead of the Mobile World Congress (MWC) in Barcelona including a camera-focused flagship smartphone, an AirTag clone, Xiaomi Watch 5 smartwatch, and an ultra slim power bank.\n\nThe China-based company has partnered with camera maker Leica to co-brand its Xiaomi 17 Ultra smartphone. As part of the partnership, it is using Leica lenses and creating filters in the style of the German camera company.\n\nThe phone has a 50-megapixel main sensor with an F/1.67 aperture and a 1-inch sensor. But the main attraction is the 200-megapixel telephoto camera that has a variable focal length of 75mm-100mm equivalent. That means you can zoom optically between 3.2x and 4.3x. The phone also has a 50 MP ultrawide camera with an f/2.2 aperture.\n\nAlso notable: The phone packs a 6,000 mAh battery (the Chinese version comes with a bigger 6,800mAh battery). The phone could be charged using a 90W USB PD-PPS, and it supports Xiaomi’s Hypercharge wireless tech at 50W.\n\nThe device has a 6.9-inch Xiaomi HyperRGB OLED display protected by Xiaomi’s own Shield Glass 3.0. The company has picked Qualcomm’s latest Snapdragon 8 Elite Gen 5 processor, which was also used in the recently launched Galaxy S26 series.\n\nThe company is also releasing a special Leica edition phone to celebrate 100 years of the camera company. The device has a durable aluminum-alloy body with a nickel-anodized finish. Xiaomi has also added a Leica theme on the software side.\n\nThe device has a rotating ring that mimics zoom on a physical camera. The special edition also has a “Leica Essential mode,” which has filters that recreate photos in the style of Leica M9 and Leica M3.\n\nXiaomi launched the Xiaomi 17 with a larger 6,330 mAh battery, which can be charged at 100W using  the company’s HyperCharge tech.\n\nThe company is also launching two photography add-ons for the Xiaomi 17 Ultra. The 17 Ultra Photography Kit is a Bluetooth-connected snap-on that has a two-stage shutter button and a video recording button.The Xiaomi 17 Ultra Photography Kit Pro aims to mimic a physical camera with a leather finish, a video recording button, a detachable shutter button, and zoom control. This kit snaps on using a USB-C connection and also has a 2,000 mAh battery for its operation. Using this add-on, users can also use a new fastshot mode on the phone.\n\nThrough this launch, the company is making these devices available in the EU and the UK. The Xiaomi 17 starts at €999, and the Xiaomi 17 Ultra starts at €1,499. The Leica edition comes with 16GB RAM and 1TB storage, and is priced at  €1,999. The Xiaomi 17 Ultra Photography Kit is priced at €99.99, and the Xiaomi 17 Ultra Photography Kit Pro is priced at €199.99.\n\nApart from phones, the company also launched a bunch of other devices, including a scooter. Xiaomi said that its Electric Scooter 6 Ultra has 1200W peak power and 75km of range. The scooter has 12-inch all-terrain tires with front and rear disc brakes. It has a three-inch TFT display to measure things like speed and range. The scooter starts at €329.99 with five different versions, with the top version priced at €799.99.\n\nThe company also launched a new Xiaomi tag, an AirTag-like device, which works with both Apple Find My and Google Android Find Hub. The tag weighs just 10 grams and has a button cell battery that lasts over a year. You can also play a sound remotely to find the tag or the time at which the tag is attached. The company is pricing this tag at €14.9 for one and €49.99 for a pack of four.\n\nWhat’s more, the company released a slim power bank with just 6mm of thickness. The powerbank weighs 98 grams and has a 5,000 mAh battery capacity. It can charge devices at 22.5W through a wired connection and at 15W through a wireless connection. The powerbank is magnetic, so it can stick to supporting phones like iPhones, and charge them wirelessly. The powerbank is priced at €59.99 for black and silver colorways. It also has an orange colorway priced at €64.99.\n\nXiaomi launched its new smartphone, Xiaomi Watch 5, with a 930mAh battery that could last up to six days. The smartwatch has a round 1.54-inch AMOLED display and supports gestures to dismiss calls or alarms. The watch can also prepare a health report in 60 seconds by using metrics like heart rate, blood oxygen, stress levels, sleep duration, sleep heart rate, and sleep SpO₂. The watch is priced at €299.99.\n\nThe company also launched a €69.9 Redmi Buds 8 Pro earbuds with active noise cancellation and up to 33 hours of battery life.",
      "excerpt": "Xiaomi today launched a slew of gadgets ahead of the Mobile World Congress (MWC) in Barcelona including a camera-focused flagship smartphone, an AirTag clone, Xiaomi Watch 5 smartwatch, and an ultra slim power bank.\n\nThe China-based company has partnered with camera maker Leica to co-brand its Xiaom",
      "tags": [
        "Apple",
        "Amazon",
        "Cloud Computing",
        "EVs",
        "Google"
      ]
    },
    {
      "title": "Why China’s humanoid robot industry is winning the early market",
      "link": "https://techcrunch.com/2026/02/28/why-chinas-humanoid-robot-industry-is-winning-the-early-market/",
      "author": "Kate Park",
      "date": "2026-02-28T07:00:00-08:00",
      "image": "https://techcrunch.com/wp-content/uploads/2025/01/GettyImages-1287582736.jpg?resize=1200,657",
      "category": "Hardware",
      "content": "China’s humanoid robots grabbedglobal attentionwith kung fu flips at the nation’s televised Spring Festival Gala, while Chinese phone maker Honor is set tounveil its first humanoid robotat MWC in Spain.\n\nRobotics was flagged as a priority under the country’s“Made in China 2025” plan, albeit originally focused on factory automation, rather than humanoids. Now, rapid advances in multimodal AI are accelerating so-called embodied AI — autonomous machines operating in the real world — a push officials say could help offset labor shortages and drive productivity gains.\n\nAt this early stage of humanoid robot development, Chinese companies are outpacing their U.S. rivals in both speed and volume, Selina Xu, a China and AI policy lead at the office of Eric Schmidt said.\n\n“China has a more robust hardware supply chain — much of it built up through the EV sector, from sensors to batteries — and the world’s strongest manufacturing base, allowing companies to iterate far faster than Western competitors,” Xu told TechCrunch.\n\nAs a result, not only are Chinese robots cheaper but companies can also release new models more quickly, Xu noted, adding that leading Chinese player Unitree shipped roughly 36 times more units last year than U.S. rivals Figure and Tesla.\n\nGlobal humanoid robot shipments totaled just 13,317 units last year,according to a Forbesreport released last month. That is a tiny base for an industry expected to nearly double annually and reach 2.6 million units by 2035. (Still, the figures should be viewed with caution. The report notes it remains unclear how many units represent commercial sales versus demo models or pilot deployments, underscoring the early-stage nature of the industry.)\n\nThe top humanoid robot makers by 2025 shipments were led by China’s Agibot and Unitree, followed by UBTech, Leju Robotics, Engine AI, and Fourier Intelligence, underscoring Beijing’s early dominance in the sector.\n\nThe biggest shift recently has been from “demo-driven excitement” to “operations-driven adoption,” Yuli Zhao, chief strategy officer at Galbot, told TechCrunch. Galbot’s humanoid robot, the G1, appeared at this year’s Spring Festival Gala, China’s annual, state-run lunar New Year’s Eve television show, alongside robots fromUnitree Robotics, Noetix, and MagicLab.\n\n“More customers are asking: Can the robot run stably in real environments and actually take work off people’s plates? That practical pull is strengthened in China because policy and industrial strategy encourage automation upgrades, and the manufacturing ecosystem makes iteration extremely fast,” Zhao said.\n\nWhile increased funding toward humanoid startups “has definitely accelerated” the pace of progress, “the most durable adoption comes when you can show reliable and repeatable value in production or service operations, not just a one-off showcase,” Zhao added.\n\nStill, investing helps and Chinese robotics makers are securing it. Last year Unitree was valued at around $3 billion after closing its Series C, with ambitions to reach as much as$7 billion in a future IPO. Meanwhile,Galbothas raised more than $300 million in fresh funding, reportedly pushing its valuation to $3 billion, one of the largest financings in China’s humanoid robotics sector to date.\n\nU.S. companies are moving beyond flashy demos as well to focus on real-world deployments. Plus, they are pursuing their own aggressive goals.U.S. startup Foundation, for instance, plans to build 50,000 humanoid robots by the end of 2027.\n\nBut China is already targeting a mix of affordable mass-market models and high-end applications, rapidly expanding humanoids across industrial, consumer, and rehabilitation sectors, according to a DecemberTrendForce report.\n\nWhen it comes to AI systems and integrated software, it’s still unclear where Chinese humanoid firms truly stand. The industry is largely betting on vision-language-action models and “world models,” but both technologies remain in early stages. Nvidia currently leads the space with its end-to-end humanoid software stack, according to Xu, so naturally most humanoid startups in China are powered by Nvidia’s Orin chips. However, domestic chipmakers are developing homegrown alternatives, she said.\n\nYet humanoid robotics makers are still working on fundamental problems. The challenge is enabling robot foundation models to predict the “next physical state” the robot will face in unpredictable environments, like how large language models predict the next word. But unlike LLMs, humanoid robotics companies can’t simply scrape the internet for training data, Xu said. So most are relying on simulation environments, which generates synthetic data, though real-world data collection remains essential.\n\n“Because of the data scarcity problem, humanoids are still far away from autonomy. The hardware is currently ahead of the software — the robot body can handle a lot more dexterity today than years ago (though it has reliability issues, as we saw with the robots that broke down at humanoid marathons), but the brain is still nascent,” the analyst said.\n\nSafety is a major hurdle for humanoid robots, too. One high-profile accident could trigger public backlash, and China is likely weighing how to roll out the technology quickly without moving too fast. As the industry matures, more regulations are expected.\n\nGiven the lack of data, Zhao believes that demand for humanoids will grow first in fairly contained workplaces.\n\n“Early momentum is likely to be in industrial manufacturing, warehouse logistics, and retail, where tasks are repetitive, hours are long, and processes are clear — creating real demand and ideal conditions for humanoid robots to deliver value at scale,” he said.\n\nHumanoid robot development is not a two-country race. Japan’s robotics ecosystem — from startups to semiconductor heavyweights — istargeting humanoid mass production by 2027. Long a pioneer through projects like Honda’s Asimo, Murata Manufacturing’s Murata Boy, and SoftBank Robotics’ Pepper, Japan leans on precision and advanced control. One area unique to this nation: Humanoid robots are increasingly used in eldercare.\n\nCoral Capital CEO James Riney, who invests in tech companies in Japan, believes Tokyo will continue to thrive in the humanoid robotics industry. “There are three factors likely to drive the adoption of robotics in Japan. One is the labor shortage and the desire to depend less on mass immigration. The second is the widespread cultural view of robots as our friends — more Doraemon vs. Terminator. The third is that Japan is already dominant in many parts of the robotics supply chain.”\n\nHyundai Motor’s Boston Dynamics unitintroduced a new Atlas humanoid for factory use by 2028, with plans to produce up to30,000 units annually in the U.S.as part of its AI-driven robotics push.\n\nStill, for China, government policy, industrial strategy, labor shortages, and private capital are all converging to turbocharge the country’s humanoid robotics push.\n\n“China’s leadership is best understood as a speed-to-scale advantage,” Zhao said. “The ecosystem here compresses the entire cycle — R&D, supply chain, manufacturing, integration, and customer deployment — into a very tight loop. That means humanoid companies can move from prototype to real-world deployment faster, learn from real operations, and iterate at a pace that’s difficult to match elsewhere.”",
      "excerpt": "China’s humanoid robots grabbedglobal attentionwith kung fu flips at the nation’s televised Spring Festival Gala, while Chinese phone maker Honor is set tounveil its first humanoid robotat MWC in Spain.\n\nRobotics was flagged as a priority under the country’s“Made in China 2025” plan, albeit original",
      "tags": [
        "Apple",
        "Amazon",
        "Cloud Computing",
        "EVs",
        "Google"
      ]
    },
    {
      "title": "Pentagon moves to designate Anthropic as a supply-chain risk",
      "link": "https://techcrunch.com/2026/02/27/pentagon-moves-to-designate-anthropic-as-a-supply-chain-risk/",
      "author": "Russell Brandom",
      "date": "2026-02-27T13:53:14-08:00",
      "image": "https://techcrunch.com/wp-content/uploads/2025/07/GettyImages-2225249178.jpg?w=1024",
      "category": "AI",
      "content": "In a post on Truth Social, President Trump directed federal agencies to cease use of all Anthropic products after the company’spublic dispute with the Department of Defense. The president allowed for a six-month phase-out period for departments using the products, but emphasized that Anthropic was no longer welcome as a federal contractor.\n\n“We don’t need it, we don’t want it, and will not do business with them again,” the president wrote in the post.\n\npic.twitter.com/B51SWfn81N\n\nNotably, the president’s post did not mention any plans to designate Anthropic as a supply chain risk, as had been previously mentioned as a consequence. However,a subsequent tweetfrom Secretary of Defense Pete Hegseth made good on the threat.\n\n“In conjunction with the President’s directive for the Federal Government to cease all use of Anthropic’s technology, I am directing the Department of War to designate Anthropic a Supply-Chain Risk to National Security,” Secretary Hegseth wrote. “Effective immediately, no contractor, supplier, or partner that does business with the United States military may conduct any commercial activity with Anthropic.”\n\nAnthropic said Fridaythat while the company has not heard from the government directly, it will “challenge any supply chain risk designation in court.”\n\nThe Pentagon dispute centered on Anthropic’s refusal to allow its AI models to be used to power either mass domestic surveillance or fully autonomous weapons, which Secretary Hegseth found unduly restrictive.\n\nCEO Dario Amodei reiterated his stancein a public post on Thursday, refusing to compromise on the two points.\n\n“Our strong preference is to continue to serve the Department and our warfighters — with our two requested safeguards in place,” Amodei wrote at the time. “Should the Department choose to offboard Anthropic, we will work to enable a smooth transition to another provider, avoiding any disruption to ongoing military planning, operations, or other critical missions.”\n\nOpenAI reportedly came out in support of Anthropic’s decision.Per the BBC, CEO Sam Altman sent a memo to staff on Thursday saying he shared the same “red lines” and that any OpenAI-related defense contracts would also reject uses that were “unlawful or unsuited to cloud deployments, such as domestic surveillance and autonomous offensive weapons.”\n\nOpenAI co-founder Ilya Sutskever, who very publicly fell out with Altman inNovember 2023and has since co-founded his own AI company, also waded into the conversation on Friday,writing on X: “It’s extremely good that Anthropic has not backed down, and it’s significant that OpenAI has taken a similar stance.”\n\nBut within hours of the Trump administration ordering federal agencies to cut ties with Anthropic, OpenAI moved to fill the void,announcing a deal with the Pentagonthat Altman said preserved the same core principles Anthropic had fought for — prohibitions on domestic surveillance and autonomous weapons.\n\nAccording to the New York Times, OpenAI and the government began meeting about a potential tie-up on Wednesday of this week.\n\nSurely, there will be more twists to come.\n\nAnthropic, OpenAI and Google each receivedcontract awardsfrom the U.S. Defense Department last July. While someGoogle employeeshave come out in support of Anthropic, Google and its parent company have yet to comment.\n\nUpdate: This story has been updated with additional reporting.",
      "excerpt": "In a post on Truth Social, President Trump directed federal agencies to cease use of all Anthropic products after the company’spublic dispute with the Department of Defense. The president allowed for a six-month phase-out period for departments using the products, but emphasized that Anthropic was n",
      "tags": [
        "Apple",
        "Amazon",
        "Cloud Computing",
        "EVs",
        "Google"
      ]
    },
    {
      "title": "What to know about the landmark Warner Bros. Discovery sale",
      "link": "https://techcrunch.com/2026/02/28/warner-bros-netflix-paramount-acquisition-timeline-wbd/",
      "author": "Lauren Forristal",
      "date": "2026-02-28T13:28:06-08:00",
      "image": "https://techcrunch.com/wp-content/uploads/2024/10/GettyImages-1574594892.jpg?resize=1200,800",
      "category": "Media & Entertainment",
      "content": "The streaming and entertainment industry just witnessed one of its most high-stakes megadeals ever, stunning industry observers. Not only is it historic in its size, but it is also predicted to disrupt Hollywood and the media business as we know it.\n\nAfter years of Warner Bros. Discovery struggling under the weight of billions of dollars in debt, compounded bydeclining cable viewershipand fierce competition from streaming platforms, the company has been considering major strategic changes, including selling its entertainment assets to one of its rivals.\n\nSeveral major players saw the potential in acquiring the media giant and in December, Netflixannounced it would acquireWBD’s studios and streaming for $82.7 billion.\n\nBut in a surprise eleventh-hour move this month, it now looks like the David Ellison-runParamount will actually be the winnerof this bidding war, offering $111 billion to acquire all of Warner Bros. Discovery’s assets, including its studios, HBO, streaming platforms, games, and TV networks such as CNN and HGTV. Paramount was itself recently acquired by Ellison with significant support from his father, the Oracle chairman, world’s sixth-richest person, and major Trump donor Larry Ellison.\n\nParamount’s offer still awaits formal approval from WBD’s board of directors, and any potential agreement may also face pressure from regulators.\n\nLet’s break down exactly what is happening, what’s at stake, and what could come next.\n\n​This all started back in October when Warner Bros. Discovery (WBD)revealed it was exploring a potential saleafter receiving unsolicited interest from several major players in the industry.\n\n​The bidding process quickly became competitive, and Paramount and Comcast emerged as serious contenders, withParamountinitially viewed as the frontrunner.\n\nHowever, WBD’s board eventually determined that an offer from the streaming giant Netflix was the most attractive. Netflix offered $82.7 billion for just Warner’s film, television, and streaming assets.\n\nThus began the bidding war. Paramount believed its bid, of approximately $108 billion for all of Warner’s assets, was superior to Netflix’s offer that focused on just the studios and streaming. To sweeten its deal, Netflixamended its agreementin January to an all-cash offer at $27.75 per share of Warner Bros. Discovery, further reassuring investors and paving the way for the deal to proceed.\n\n​Paramountpersisted in its attempts to acquire WBD. Still, the Warner board repeatedlyrejectedits offers, citing concerns about Paramount’s heavy debt load and the increased risk associated with its proposal, including concern over the suite of investors bankrolling Paramount’s bid, which includes Saudi, Qatari, and Abu Dhabi sovereign wealth funds. The board noted that Paramount’s offer would have left the combined company burdened with $87 billion in debt, a risk they were unwilling to take at the time.\n\nIn January, Paramountfiled a lawsuitseeking more information about the Netflix deal. A month later, the company sought to sweeten its deal byannouncingit would offer a $0.25 per share “ticking fee” to WBD shareholders for each quarter the deal fails to close by December 31, 2026. It also said it would pay the $2.8 billion breakup fee if Warner backs out of its deal with Netflix.\n\nThen, in a final attempt to secure a deal, Paramount increased its offer to $31 per share in February. This prompted the WBD board toprolong discussionswith Paramount regarding a potential agreement, considering it as a superior offer. Netflix declined to increase its bid and withdrew from the negotiations.\n\n“The transaction we negotiated would have created shareholder value with a clear path to regulatory approval,” Netflix co-CEOs Ted Sarandos and Greg Peterssaid in a statementon Feb. 26. “However, we’ve always been disciplined, and at the price required to match Paramount Skydance’s latest offer, the deal is no longer financially attractive, so we are declining to match the Paramount Skydance bid.”\n\nIn addition to the billions Paramount already holds in debt, the company is also set to assume the approximately $33 billion in debt Warner Bros. Discovery holdsunder the agreement. The deal will bebackedby a $54 billion debt commitment from Bank of America Merrill Lynch, Citi, and Apollo Global Management, as well as $45.7 billion in equity from Larry Ellison.\n\nIn addition to the assumption of substantial debt posing a significant financial burden, Paramount faces several other hurdles in its deal with WBD that could impact the success of the transaction.\n\nFor one, Ellison has warned about significant job reductions that are expected in the near future. There have already beenwidespread concerns among criticsabout potential job lossesand lower wages.\n\nEllison is also a controversial figure in the industry, and his ownership of CBS News has been seen as sympathetic and supportive of the administration of Donald Trump, of whom his father, Larry Ellison, is a major donor. Under Ellison’s ownership of Paramount, reporting critical of the administration has been shelved or received increased scrutiny from Ellison or his appointed head of CBS News, the conservative provocateur Bari Weiss.\n\nThis has led to some concern among employees at Warner-owned CNN. Trump has personally sought concessions from news divisions critical of him, including a$16 million settlement from CBS, before his FCCwould approvethe Ellison takeover of Paramount. Before Netflix bowed out of the deal, Trumppressured the companyto fire the former Biden White House official Susan Rice from its board. He has publicly stated his intentions tobring CNN to heelunder new owners.\n\nRegulatory scrutiny is another hurdle. Such a large-scale merger has attracted attention from lawmakers.\n\nFor instance, California Attorney General Rob Bontasaid in a statementon February 26 that “these two Hollywood titans have not cleared regulatory scrutiny — the California Department of Justice has an open investigation, and we intend to be vigorous in our review.”\n\nA day before Netflix backed out, it was revealed that acoalition of 11 state attorneys generalurged the U.S. Department of Justice (DOJ) to review the merger under concerns it will stifle competition and increase subscription prices. This comes months after U.S. senators Elizabeth Warren, Bernie Sanders, and Richard Blumenthal voicedtheir concerns to the Justice Department’s Antitrust Division, warning that such a massive merger could have serious consequences for consumers and the industry at large. The senators argue that the merger could give the new media giant excessive market power, enabling it to raise prices for consumers and stifle competition.\n\nThat said, Ellison’s father, the Oracle chairman Larry Ellison, is a significant Trump donor and has close ties to the Trump administration. His deal to acquire Paramount last year cleared quickly after acquiescing to c\n\nThe deal is not yet final.\n\nInitially, a deal with Netflix was expected to lead to a stockholder vote around April, with the deal anticipated to close within 12 to 18 months following that vote. However, the transition to the Paramount deal will likely create a new timeline for approval. Plus, regulatory approvals are still pending, and scrutiny could shape the final outcome.\n\nStay tuned…",
      "excerpt": "The streaming and entertainment industry just witnessed one of its most high-stakes megadeals ever, stunning industry observers. Not only is it historic in its size, but it is also predicted to disrupt Hollywood and the media business as we know it.\n\nAfter years of Warner Bros. Discovery struggling ",
      "tags": [
        "Apple",
        "Amazon",
        "Cloud Computing",
        "EVs",
        "Google"
      ]
    },
    {
      "title": "India disrupts access to popular developer platform Supabase with blocking order",
      "link": "https://techcrunch.com/2026/02/27/india-disrupts-access-to-popular-developer-platform-supabase-with-blocking-order/",
      "author": "Jagmeet Singh",
      "date": "2026-02-27T19:51:52-08:00",
      "image": "https://techcrunch.com/wp-content/uploads/2026/02/supabase.jpg?resize=1200,800",
      "category": "Government & Policy",
      "content": "Supabase, a popular developer database platform, is facing disruptions in India — one of its key markets — has been blocked in India, TechCrunch has learned. New Delhi ordered internet providers to block its website, resulting in patchy access across networks.\n\nThe blocking order was issued on February 24 under Section 69A of India’s Information Technology Act, according to a source familiar with the matter. The provision empowers the government to restrict public access to online content.\n\nThe Indian government did not publicly cite a reason for the move, and it was not immediately clear whether the action was linked to a cybersecurity concern, copyright complaint, or another issue. It was also unclear how long the restrictions would remain in place.\n\nAccess to Supabase has been inconsistent in India over the past several days, with the San Francisco-based companyacknowledging the issuein posts on social media starting Wednesday. While the restrictions were first reported by Supabase on Reliance Industries’ JioFiber network, users have since flagged similar problems across multiple internet providers and telecom networks. In one post on Friday, Supabase tagged India’s IT minister Ashwini Vaishnaw, asking him to intervene and restore access, though the company later removed the message and said in a subsequent update that the site remained blocked for many users in the country.\n\nWe understand many users in India continue to be blocked from accessing Supabase. We acknowledge the difficulties this is causing for our users there. Supabase continues to follow up through all available channels to resolve this issue.We continue to advise affected customers…\n\nAn Indian founder, who asked not to be named to avoid potential repercussions, told TechCrunch they had stopped seeing new user sign-ups from India over the past two to three days. A technology consultant working with local startups, who spoke on condition of anonymity, said they were unable to reliably access Supabase for both development and production purposes.\n\nWhile Supabase suggested workarounds such as switching DNS settings or using a VPN (which reroute internet traffic to bypass local restrictions), the founder said such steps were not practical for most end users.\n\nAt the time of publication, TechCrunch was able to verify that supabase.co remained inaccessible on ACT Fibernet, JioFiber and Airtel connections in New Delhi. However, two users on ACT Fibernet in Bengaluru said they were still able to access the service, suggesting the restrictions may be unevenly implemented.\n\nNotably, Supabase’smain websiteremained accessible in India — but its underlying developer infrastructure did not.\n\nIndia is Supabase’s fourth-largest source of traffic, accounting for about 9% of global visits, according to data from Similarweb, highlighting the potential fallout for the country’s developer ecosystem. The platform’s global traffic jumped more than 111% year over year to about 4.2 million visits in January. In India, visits rose roughly 179% to about 365,000, compared with a 168.5% increase in the U.S. to about 627,000.\n\nThe incident highlights broader concerns about India’s website blocking regime, said Raman Jit Singh Chima, Asia Pacific policy director at Access Now.\n\n“This is a simple fact that has grave consequences for developers and others,” he told TechCrunch. “You don’t know where you can safely run projects without the danger that something might happen where it gets blocked, and suddenly you’re scrambling to find a way.”\n\nIndia has previously faced criticism over broad website blocking measures. In 2014, authorities briefly restrictedaccess to developer platform GitHub, along with services such as Vimeo, Pastebin and Weebly, during a security probe. Users on some Indian networks in 2023 alsoreportedthat a key GitHub content domain had been blocked by certain ISPs, according to earlier reports.\n\nFounded in 2020 by CEO Paul Copplestone and CTO Ant Wilson, Supabase positions itself as an open-source alternative to Firebase built on PostgreSQL. The startup hasgained tractionamid rising interest in so-called “vibe coding” tools and AI-driven app development, and has raised about $380 million across three funding rounds since September 2024, lifting itsvaluation to $5 billion.\n\nIndia’s Ministry of Electronics and IT, as well as telecom providers including ACT Fibernet, Bharti Airtel, and Reliance Jio, did not respond to requests for comment. Copplestone and Wilson also did not respond.",
      "excerpt": "Supabase, a popular developer database platform, is facing disruptions in India — one of its key markets — has been blocked in India, TechCrunch has learned. New Delhi ordered internet providers to block its website, resulting in patchy access across networks.\n\nThe blocking order was issued on Febru",
      "tags": [
        "Apple",
        "Amazon",
        "Cloud Computing",
        "EVs",
        "Google"
      ]
    },
    {
      "title": "Musk bashes OpenAI in deposition, saying ‘nobody committed suicide because of Grok’",
      "link": "https://techcrunch.com/2026/02/27/musk-bashes-openai-in-deposition-saying-nobody-committed-suicide-because-of-grok/",
      "author": "Sarah Perez",
      "date": "2026-02-27T11:42:00-08:00",
      "image": "https://techcrunch.com/wp-content/uploads/2024/11/GettyImages-2183887189.jpg?resize=1200,800",
      "category": "AI",
      "content": "In a newly released deposition filed in Elon Musk’s case against OpenAI, the tech executive attacked OpenAI’s safety record, claiming that his company, xAI, better prioritizes safety.  He went so far as to say that “Nobody has committed suicide because of Grok, but apparently they have because of ChatGPT.”\n\nThe comment came up in a line of questioning about apublic letterMusk signed in March 2023. In it, he called on AI labs to pause development of AI systems more powerful than GPT-4, OpenAI’s flagship model at the time, for at least six months. The letter, which was signed by over 1,100 people, including many AI experts, stated there was not enough planning and management taking place at AI labs, as they were locked in an “out-of-control race to develop and deploy ever more powerful digital minds that no one — not even their creators — can understand, predict, or reliably control.”\n\nThose fears have since gained credibility. OpenAI now faces aseries of lawsuitsalleging thatChatGPT’s manipulative conversation tacticshave led several people to experience negative mental health effects, with some dying by suicide. Musk’s comment suggests that these incidents could be used as fodder in his case against OpenAI.\n\nThe transcript of Musk’s video testimony, which took place back in September, was filed publicly this week, ahead of the expected jury trial next month.\n\nThelawsuitagainst OpenAI centers on the company’s shift from a nonprofit AI research lab to a for-profit company, whichMusk claims violatedits founding agreements. As part of his arguments, Musk claims that AI safety could be compromised by OpenAI’s commercial relationships, as such relationships would place speed, scale, and revenue above safety concerns.\n\nHowever, since that recording, xAI has faced safety concerns of its own. Last month, Musk’s social network X wasflooded with nonconsensual nude imagesgenerated by xAI’s Grok, some of whichwere said to be of minors. This led the California Attorney General’s office toopen an investigationinto the matter. The EU is alsorunning its own investigation, and other governments have taken action, too, with some imposing blocks and bans.\n\nIn the newly filed deposition, Musk claimed he had signed the AI safety letter because “it seemed like a good idea,” not because he had just incorporated an AI company looking to compete with OpenAI.\n\n“I signed it, as many people did, to urge caution with AI development,” Musk said. “I just wanted … AI safety to be prioritized.”\n\nMusk also responded to other questions in the deposition, including those about artificial general intelligence, or AGI — the concept of AI that can match or surpass human reasoning across a broad range of tasks — saying “it has a risk.” He also confirmed that he “was mistaken” about hissupposed $100 million donationto OpenAI; thesecond amended complaintin the case puts the actual figure closer to $44.8 million.\n\nHe also recalled why OpenAI was founded, which, from his perspective, was because he was “increasingly concerned about the danger of Google being a monopoly in AI,” adding that his conversations with Google co-founder Larry Page were “alarming, in that he did not seem to be taking AI safety seriously.” OpenAI was formed as a counterweight to that threat, Musk claimed.",
      "excerpt": "In a newly released deposition filed in Elon Musk’s case against OpenAI, the tech executive attacked OpenAI’s safety record, claiming that his company, xAI, better prioritizes safety.  He went so far as to say that “Nobody has committed suicide because of Grok, but apparently they have because of Ch",
      "tags": [
        "Apple",
        "Amazon",
        "Cloud Computing",
        "EVs",
        "Google"
      ]
    },
    {
      "title": "Why did Netflix back down from its deal to acquire Warner Bros.?",
      "link": "https://techcrunch.com/2026/02/28/why-did-netflix-back-down-from-its-deal-to-acquire-warner-bros/",
      "author": "Anthony Ha",
      "date": "2026-02-28T14:07:48-08:00",
      "image": "https://techcrunch.com/wp-content/uploads/2023/02/GettyImages-1240099721.jpeg?resize=1200,800",
      "category": "",
      "content": "Netflix stunned the entertainment world this week when itdeclined to raise its bid for Warner Bros. Discovery, setting the stage for Paramount Skydance to win ownership of the Hollywood studio.\n\nAt the time, Netflix co-CEOs Ted Sarandos and Greg Peters said they were being financially disciplined. Nowreporting in Bloombergoffers more details about why Netflix executives backed down froma bidding war that it seemed to win back in December.\n\nFor one thing, the streaming giant’s shareholders appeared deeply skeptical that the acquisition was a good deal — Netflix’s share price declined 30% since announcing the deal, while the subsequent news that it was backing downsent Netflix stock up nearly 14%.\n\nFor another, Netflix’s commitment to the deal reportedly wavered after Paramount came in with an increased offer and seemed willing to go several more rounds in a bidding war.\n\nBy the time Sarandos met with Trump administration officials on Thursday, he may already have decided to concede. In fact, since President Donald Trump had previously warned him not to overpay, Sarandos reportedly told him, “I took your advice.”\n\nMeanwhile, employees at Warner Bros. now worry aboutmajor studio layoffsandconservative political pressure on CNN.",
      "excerpt": "Netflix stunned the entertainment world this week when itdeclined to raise its bid for Warner Bros. Discovery, setting the stage for Paramount Skydance to win ownership of the Hollywood studio.\n\nAt the time, Netflix co-CEOs Ted Sarandos and Greg Peters said they were being financially disciplined. N",
      "tags": [
        "Apple",
        "Amazon",
        "Cloud Computing",
        "EVs",
        "Google"
      ]
    },
    {
      "title": "Anthropic’s Claude rises to No. 2 in the App Store following Pentagon dispute",
      "link": "https://techcrunch.com/2026/02/28/anthropics-claude-rises-to-no-2-in-the-app-store-following-pentagon-dispute/",
      "author": "Anthony Ha",
      "date": "2026-02-28T13:05:06-08:00",
      "image": "https://techcrunch.com/wp-content/uploads/2024/12/Claude-ad-e1733259907871.jpg?resize=1200,800",
      "category": "",
      "content": "Anthropic’s chatbot Claude seems to have benefited from the attention around the company’s fraught negotiations with the Pentagon.\n\nAsfirst reported by CNBC, as of Saturday afternoon, Claude is currently ranked number two among free apps in Apple’s US App Store — the number one app is OpenAI’s ChatGPT, and number three is Google Gemini.\n\nAccording todata from SensorTower, Claude was just outside the top 100 at the end of January, and has spent most of February somewhere in the top 20. Its ranking has climbed in the last few days, from sixth on Wednesday to fourth on Thursday to second on Saturday (today).\n\nAfter Anthropic attempted to negotiate for safeguards preventing the Department of Defense from using its AI models for mass domestic surveillance or fully autonomous weapons, President Donald Trump directed federal agencies to stop using all Anthropic products and Secretary of Defense Pete Hegseth said he’sdesignating the company a supply-chain threat.\n\nOpenAI subsequentlyannounced its own agreement with the Pentagon, which CEO Sam Altman claimed includes safeguards related to domestic surveillance and autonomous weapons.",
      "excerpt": "Anthropic’s chatbot Claude seems to have benefited from the attention around the company’s fraught negotiations with the Pentagon.\n\nAsfirst reported by CNBC, as of Saturday afternoon, Claude is currently ranked number two among free apps in Apple’s US App Store — the number one app is OpenAI’s ChatG",
      "tags": [
        "Apple",
        "Amazon",
        "Cloud Computing",
        "EVs",
        "Google"
      ]
    }
  ]
}