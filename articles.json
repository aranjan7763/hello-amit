{
  "last_updated": "2026-02-27T20:31:37.498759+00:00",
  "articles": [
    {
      "title": "Musk bashes OpenAI in deposition, saying ‘nobody committed suicide because of Grok’",
      "link": "https://techcrunch.com/2026/02/27/musk-bashes-openai-in-deposition-saying-nobody-committed-suicide-because-of-grok/",
      "author": "Sarah Perez",
      "date": "2026-02-27T11:42:00-08:00",
      "image": "https://techcrunch.com/wp-content/uploads/2024/11/GettyImages-2183887189.jpg?resize=1200,800",
      "category": "AI",
      "content": "In a newly released deposition filed in Elon Musk’s case against OpenAI, the tech executive attacked OpenAI’s safety record, claiming that his company, xAI, better prioritizes safety.  He went so far as to say that “Nobody has committed suicide because of Grok, but apparently they have because of ChatGPT.”\n\nThe comment came up in a line of questioning about apublic letterMusk signed in March 2023. In it, he called on AI labs to pause development of AI systems more powerful than GPT-4, OpenAI’s flagship model at the time, for at least six months. The letter, which was signed by over 1,100 people, including many AI experts, stated there was not enough planning and management taking place at AI labs, as they were locked in an “out-of-control race to develop and deploy ever more powerful digital minds that no one — not even their creators — can understand, predict, or reliably control.”\n\nThose fears have since gained credibility. OpenAI now faces aseries of lawsuitsalleging thatChatGPT’s manipulative conversation tacticshave led several people to experience negative mental health effects, with some dying by suicide. Musk’s comment suggests that these incidents could be used as fodder in his case against OpenAI.\n\nThe transcript of Musk’s video testimony, which took place back in September, was filed publicly this week, ahead of the expected jury trial next month.\n\nThelawsuitagainst OpenAI centers on the company’s shift from a nonprofit AI research lab to a for-profit company, whichMusk claims violatedits founding agreements. As part of his arguments, Musk claims that AI safety could be compromised by OpenAI’s commercial relationships, as such relationships would place speed, scale, and revenue above safety concerns.\n\nHowever, since that recording, xAI has faced safety concerns of its own. Last month, Musk’s social network X wasflooded with nonconsensual nude imagesgenerated by xAI’s Grok, some of whichwere said to be of minors. This led the California Attorney General’s office toopen an investigationinto the matter. The EU is alsorunning its own investigation, and other governments have taken action, too, with some imposing blocks and bans.\n\nIn the newly filed deposition, Musk claimed he had signed the AI safety letter because “it seemed like a good idea,” not because he had just incorporated an AI company looking to compete with OpenAI.\n\n“I signed it, as many people did, to urge caution with AI development,” Musk said. “I just wanted … AI safety to be prioritized.”\n\nMusk also responded to other questions in the deposition, including those about artificial general intelligence, or AGI — the concept of AI that can match or surpass human reasoning across a broad range of tasks — saying “it has a risk.” He also confirmed that he “was mistaken” about hissupposed $100 million donationto OpenAI; thesecond amended complaintin the case puts the actual figure closer to $44.8 million.\n\nHe also recalled why OpenAI was founded, which, from his perspective, was because he was “increasingly concerned about the danger of Google being a monopoly in AI,” adding that his conversations with Google co-founder Larry Page were “alarming, in that he did not seem to be taking AI safety seriously.” OpenAI was formed as a counterweight to that threat, Musk claimed.",
      "excerpt": "In a newly released deposition filed in Elon Musk’s case against OpenAI, the tech executive attacked OpenAI’s safety record, claiming that his company, xAI, better prioritizes safety.  He went so far as to say that “Nobody has committed suicide because of Grok, but apparently they have because of Ch",
      "tags": [
        "Apple",
        "Amazon",
        "Cloud Computing",
        "EVs",
        "Google"
      ]
    },
    {
      "title": "Perplexity’s new Computer is another bet that users need many AI models",
      "link": "https://techcrunch.com/2026/02/27/perplexitys-new-computer-is-another-bet-that-users-need-many-ai-models/",
      "author": "Tim Fernholz",
      "date": "2026-02-27T09:00:55-08:00",
      "image": "https://techcrunch.com/wp-content/uploads/2025/01/GettyImages-2181313521.jpg?w=1024",
      "category": "AI",
      "content": "Starting this week, Perplexity subscribers will have a new agentic tool at their disposal.\n\nPerplexity Computer, in the company’s words, “unifies every current AI capability into a single system.” More specifically, Perplexity says it is a computer user agent that can execute complex workflows independently using 19 different AI models, even creating subagents to handle specific problems.\n\nThe tool is available now, only on the company’s highest subscription tier, the $200/month Perplexity Max. It runs entirely in the cloud, which might spare it some of the security concerns of other agentic tools like OpenClaw.\n\nTechCrunch hasn’t done a hands-on demo of the new tool, but inexample workflowson Perplexity’s website, it is shown handling tasks that involve collecting statistics, financial, or legal data; creating analysis; and sharing its findings as finished websites or visualizations.\n\nPerplexity invited the press to a background briefing with executives last week to discuss the product and lay out the agenda for the year. The event was intended to include a demonstration of the tool, but the company canceled the demo because of flaws found in the product hours before the event.\n\nThis tool represents the evolution of Perplexity, which made a splash early in the AI boom by wrapping frontier models in familiar user interfaces, particularly its search-engine-like answer service. It then moved on to launch its Comet web browser last summer. Competitors like Google have now changed their products to be more like those built at Perplexity, one executive said, but that’s a threat as much as a compliment.\n\nThe company is changing in response to a shifting ecosystem: One of the first AI companies to offer advertising, it abandoned that business late last year, saying last week that it undermined users’ trust in their answers’ accuracy. But Perplexity’s total user base — in the tens of millions of users — pales in comparison to that of OpenAI, which claims 800 million weekly users and began testing ads in ChatGPT this year.\n\nNow, Perplexity executives say they are aiming for a more boutique set of users, with products that serve people making “GDP-moving decisions.” Executives in the briefing, who asked not to be identified by name, described prioritizing enterprise subscriptions, particularly for deep research.\n\n“You don’t hear us talk about MAUs ever, because we’re not actually on a mission to get as many users as possible,” one executive said.\n\nPerplexity recently released a new benchmark for complex research tasks, called Draco, where (no surprise) its own deep research offering beats out competitors like Gemini.\n\nPerplexity says it is no longer reliant on other companies’ APIs for its web index and now has its own AI-optimized search API. But the company is doubling down on packaging frontier models in a consumer-friendly user experience, arguing that there is value in orchestrating multiple third-party LLMs to obtain the most cost-effective and accurate answers to queries.\n\n“Multi-model is the future,” one Perplexity exec argued. Models, in their view, are specializing, not commoditizing. The company has found that its users frequently switch between models to obtain the results they are looking for, with December 2025 queries for visual outputs most often sent to Gemini Flash, software engineering done in Claude Sonnet 4.5, and medical research in GPT-5.1.\n\nIf one LLM is better at coding tasks and another does a better job drafting marketing copy, Perplexity’s software can automatically choose the ideal one. Another example, executives said, is running Perplexity’s own modified open source Chinese-built LLMs to answer queries more cheaply, a technique the company got dinged for hiding from its customers last year. But done transparently, the technique could prove an efficient way to optimize LLM queries.\n\nThe company also offers users the opportunity to query multiple models at once, in a feature called Model Council. But the unit economics of offering multiple queries at flat subscription rates aren’t entirely clear.\n\nStill, without expensive infrastructure projects on its books and with, the executives claimed, high margins on user fees, Perplexity believes it will remain competitive by allocating tokens to the best model for a purpose.\n\nAnd there is more on the horizon: Perplexity Comet browser is coming to iOS next month, and the company is planning a developers conference, Ask, on March 11 in San Francisco to promote third-party use of its API.\n\nOne executive said that instead of looking at the previous day’s number of queries each morning, he was now looking at the most recent revenue metrics. At least some customers are noticing a new focus on the bottom line, with the Perplexity subreddit featuring frequent complaints of new rate limits on free and subscription product tiers.\n\nHowever, the execs at the briefing dismiss such complaints: “Any discussions on the free tier being made worse or rate-limited is completely false,” one said.",
      "excerpt": "Starting this week, Perplexity subscribers will have a new agentic tool at their disposal.\n\nPerplexity Computer, in the company’s words, “unifies every current AI capability into a single system.” More specifically, Perplexity says it is a computer user agent that can execute complex workflows indep",
      "tags": [
        "Apple",
        "Amazon",
        "Cloud Computing",
        "EVs",
        "Google"
      ]
    },
    {
      "title": "Anthropic vs. the Pentagon: What’s actually at stake?",
      "link": "https://techcrunch.com/2026/02/27/anthropic-vs-the-pentagon-whats-actually-at-stake/",
      "author": "Rebecca Bellan",
      "date": "2026-02-27T11:11:04-08:00",
      "image": "https://techcrunch.com/wp-content/uploads/2026/02/GettyImages-2218106494.jpg?resize=1200,800",
      "category": "Government & Policy",
      "content": "The past two weeks have been defined by aclashbetween Anthropic CEO Dario Amodei and Defense Secretary Pete Hegseth as the two battle over the military’s use of AI.\n\nAnthropic refuses to allow its AI models to be used for mass surveillance of Americans or for fully autonomous weapons that conduct strikes without human input. At the same time, Secretary Hegseth has argued the Department of Defense shouldn’t be limited by the rules of a vendor, arguing any “lawful use” of the technology should be permitted.\n\nOn Thursday,Amodei publicly signaledthat Anthropic isn’t backing down — despite threats that his company could be designated as a supply chain risk as a result. But with the news cycle moving fast, it’s worth revisiting exactly what’s at stake in the fight.\n\nAt its core, this fight is about who controls powerful AI systems — the companies that build them, or the government that wants to deploy them.\n\nAs we said above, Anthropic doesn’t want its AI models to be used for mass surveillance of Americans or for autonomous weapons with no humans in the loop for targeting and firing decisions. Traditional defense contractors typically have little say in how their products will be used, but Anthropic has argued from its inception that AI technology poses unique risks and therefore requires unique safeguards. From the company’s perspective, the question is how to maintain those safeguards when the technology is being used by the military.\n\nThe U.S. military already relies on highly automated systems, some of which are lethal. The decision to use lethal force has historically been left to humans, but there are few legal restrictions on military use of autonomous weapons. The DoD doesn’t categorically ban fully autonomous weapons systems. According to a2023 DOD directive, AI systems can select and engage targets without human intervention, as long as they meet certain standards and pass review by senior defense officials.\n\nThat’s precisely what makes Anthropic nervous. Military technology is secretive by nature, so if the U.S. military were taking steps to automate lethal decision-making, we might not know about it until it was operational. And if it used Anthropic’s models, it could count as “lawful use.”\n\nAnthropic’s position isn’t that such uses should be permanently off the table. It’s that its models aren’t capable enough to support them safely yet. Imagine an autonomous system misidentifying a target, escalating a conflict without human authorization, or making a split-second lethal decision that no one can reverse. Put a less-capable AI in charge of weapons, and you get a very fast, very confident machine that’s bad at making high-stakes calls.\n\nAI also has the power to supercharge lawful surveillance of American citizens to a concerning degree. Under current U.S. laws, surveillance of American citizens is already possible, whether through collection of texts, emails, and other communication. AI changes the equation by enabling automated large-scale pattern detection, entity resolution across datasets, predictive risk scoring, and continuous behavioral analysis.\n\nThe Pentagon’s argument is that it should be able to deploy Anthropic’s technology for any lawful use it deems necessary, rather than be limited by Anthropic’s internal policies on things like autonomous weapons or surveillance.\n\nMore specifically, Secretary Hegseth has argued the Department of Defense shouldn’t be limited by the rules of a vendor and that it would engage in “lawful use” of the technology.\n\nSean Parnell, the Pentagon’s chief spokesperson, said in aThursday X postthat the department has no interest in conducting mass domestic surveillance or deploying autonomous weapons.\n\n“Here’s what we’re asking: Allow the Pentagon to use Anthropic’s model for all lawful purposes,” Parnell said. “This is a simple, common-sense request that will prevent Anthropic from jeopardizing critical military operations and potentially putting our warfighters at risk. We will not let ANY company dictate the terms regarding how we make operational decisions.”\n\nHe added that Anthropic has until 5:01 p.m. ET on Friday to decide. “Otherwise, we will terminate our partnership with Anthropic and deem them a supply chain risk for DOW,” he said.\n\nDespite the DoD’s stance that it simply doesn’t believe it should be limited by a corporation’s usage policies, Secretary Hegseth’s concerns about Anthropic have at times seemed connected to cultural grievance. Ina speech at SpaceX and xAI offices in January, Hegseth railed against “woke AI” in a speech that some saw as a preview of his feud with Anthropic.\n\n“Department of War AI will not be woke,” Hegseth said. “We’re building war-ready weapons and systems, not chatbots for an Ivy League faculty lounge.”\n\nThe Pentagon has threatened to either declare Anthropic a “supply chain risk” — which effectively blacklists Anthropic from doing business with the government — or invoke the Defense Production Act (DPA) to force the company to tailor its model to the military’s needs. Hegseth has given Anthropic until 5:01 p.m. on Friday to respond. But with the deadline approaching, it’s anyone’s guess whether the Pentagon will make good on its threat.\n\nThis is not a fight either party can easily walk away from. Sachin Seth, a VC at Trousdale Ventures who focuses on defense tech, says a supply chain risk label for Anthropic could mean “lights out” for the company.\n\nHowever, he said, if Anthropic is dropped from the DoD, it could be a national security issue.\n\n“[The Department] would have to wait six to 12 months for either OpenAI or xAI to catch up,” Seth told TechCrunch. “That leaves a window of up to a year where they might be working from not the best model, but the second or third best.”\n\nxAI is gearing up to become classified-ready and replace Anthropic, and it’s fair to say given ownerElon Musk’s rhetoricon the matter that the company would have no problem giving the DoD total control over its technology. Recentreportsindicate that OpenAI may stick to the same red lines as Anthropic.",
      "excerpt": "The past two weeks have been defined by aclashbetween Anthropic CEO Dario Amodei and Defense Secretary Pete Hegseth as the two battle over the military’s use of AI.\n\nAnthropic refuses to allow its AI models to be used for mass surveillance of Americans or for fully autonomous weapons that conduct st",
      "tags": [
        "Apple",
        "Amazon",
        "Cloud Computing",
        "EVs",
        "Google"
      ]
    },
    {
      "title": "Ultrahuman bets on redesigned smart ring to win back US market after Oura dispute",
      "link": "https://techcrunch.com/2026/02/27/ultrahuman-unveils-new-smart-ring-as-it-awaits-u-s-clearance-after-oura-dispute/",
      "author": "Jagmeet Singh",
      "date": "2026-02-27T03:00:00-08:00",
      "image": "https://techcrunch.com/wp-content/uploads/2026/02/ultrahuman-ring-pro.jpg?resize=1200,800",
      "category": "Biotech & Health",
      "content": "Ultrahuman on Friday unveiled a new smart ring with longer battery life and a redesigned form factor, as the Bengaluru-based wearable maker seeks to revive its U.S. business that was disrupted last year by a patent dispute with rival Oura.\n\nThe Ring Pro, Ultrahuman’s third-generation smart ring, offers up to 15 days of battery life — compared with four to six days on theRing Air— and is priced at $479. It will be available for preorders globally, excluding the U.S., with shipments beginning in March.\n\nUltrahuman’s U.S. business was disrupted in October 2025 after the U.S. International Trade Commission — a federal agency that handles trade disputes —ruled in Oura’s favorin a patent dispute. The ruling prevented the startup from importing new ring inventory into the country, although existing retail stock continued to be sold. The blow was significant. The U.S. accounted for about 45% of Ultrahuman’s roughly 700,000 daily active users worldwide, according to co-founder and CEO Mohit Kumar.\n\nIn August 2025, Ultrahuman alsofiled a separate patent infringement caseagainst Oura in the Delhi High Court, where the matter remains pending.\n\nMeanwhile, to work around Oura’s patent, Ultrahuman developed the Ring Pro with a new design, Kumar told TechCrunch, adding that the device has been submitted to the U.S. Customs and Border Protection for clearance to confirm it can legally be imported into the country.\n\nDespite the U.S. disruption, Ultrahuman is currently operating at an annualized revenue run rate of about $150 million, Kumar said. Itreported $64 millionin operating revenue in the financial year ended March 2025. The startup remains profitable after tax, although margins are expected to narrow due to litigation costs, tariffs, and the redesign effort, he added.\n\nAlongside the new ring, Ultrahuman introduced Jade, a real-time “biointelligence” system that analyzes user health data across its devices and services to generate personalized insights and recommendations.\n\nKumar said Jade is designed to move beyond retrospective health summaries toward real-time, actionable guidance.\n\n“Most AI tools today look backward at your data,” he said. “Jade is built to react to your health in real time and surface actions users can take.”\n\nKumar said Jade will be available to all Ultrahuman users, including those using the older Ring Air, and does not currently require a subscription.\n\nThe Ring Pro features a redesigned heart-rate sensing architecture for improved signal quality during sleep and a new dual-core processor to enhance data accuracy and on-device computing. The device can store up to 250 days of health data and weighs about 5% to 6% more than the Ring Air, launched in July 2023 at $349.\n\nUltrahuman has also introduced a Pro Charger with up to 45 days of battery life to support on-the-go charging and enable faster updates and diagnostics through direct case connectivity. The charger also supports wireless charging via Qi, the same standard used by most modern smartphones.\n\nWomen account for about 68% of Ultrahuman’s user base, up from roughly 65% a year earlier, Kumar said, reflecting strong adoption of the startup’s women’s health features.\n\nUltrahuman also offers subscription-based services across its broader health platform, including a coaching and recovery program called PowerPlugs, the Blood Vision metabolic panel, Ultrahuman Home, and a continuous glucose monitoring offering. Subscriptions contribute about 16% of Ultrahuman’s revenue, while Blood Vision accounts for roughly 5% to 6% of the business, Kumar said.\n\nUltrahuman’s key growth markets include the U.K., Canada, Australia, and India, Kumar told TechCrunch, with the latter contributing about 8% to 9% of overall revenue after recent investments in local customer support.\n\nGlobal smart ring shipments grew nearly 80% year-over-year in 2025, driven by demand for compact wearables with advanced sleep tracking and longer battery life, said Anshika Jain, senior analyst at Counterpoint Research. Oura continues to lead with more than two-thirds of the market, while Ultrahuman holds the second position.\n\nJain added that future leaders in the category will be defined by sensor accuracy, AI-driven insights, and seamless ecosystem integration.\n\nSeparate IDC data showed global smart ring shipments rising about 30% year over year in Q3 2025 to nearly 1 million units, driven in part by demand for screenless fitness trackers, said Navkendar Singh, associate vice president at IDC India. Ultrahuman captured roughly 25% of the market during the period, per IDC.\n\nFounded in 2019, Ultrahuman has raised about $55 million to date and counts Alpha Wave Incubation, Blume Ventures, Steadview Capital, and Nexus Venture Partners among its investors.\n\nUltrahuman, Kumar said, is building additional production capacity to support demand for the Ring Pro over the coming months.",
      "excerpt": "Ultrahuman on Friday unveiled a new smart ring with longer battery life and a redesigned form factor, as the Bengaluru-based wearable maker seeks to revive its U.S. business that was disrupted last year by a patent dispute with rival Oura.\n\nThe Ring Pro, Ultrahuman’s third-generation smart ring, off",
      "tags": [
        "Apple",
        "Amazon",
        "Cloud Computing",
        "EVs",
        "Google"
      ]
    },
    {
      "title": "OpenAI raises $110B in one of the largest private funding rounds in history",
      "link": "https://techcrunch.com/2026/02/27/openai-raises-110b-in-one-of-the-largest-private-funding-rounds-in-history/",
      "author": "Russell Brandom",
      "date": "2026-02-27T06:13:01-08:00",
      "image": "https://techcrunch.com/wp-content/uploads/2025/04/GettyImages-2197366846.jpg?resize=1200,800",
      "category": "AI",
      "content": "OpenAI has raised $110 billion in private funding, the companyannounced Friday morning, commencing one of the largest private funding rounds in history. The new funding consists of a $50 billion investment from Amazon as well as $30 billion each from Nvidia and SoftBank, against a $730 billion pre-money valuation.\n\nNotably, the round remains open, and OpenAI expects more investors to join as it proceeds.\n\n“We are entering a new phase where frontier AI moves from research into daily use at global scale,” OpenAI said. “Leadership will be defined by who can scale infrastructure fast enough to meet demand, and turn that capacity into products people rely on.”\n\nAs part of the investment, OpenAI is launching significant infrastructure partnerships with both Amazon and Nvidia. As in previous rounds, it is likely that a significant portion of the dollar amount comes in the form of services rather than cash, although the precise split was not disclosed.\n\nThe company’s previous round closed in March 2025, raising $40 billion against a $300 billion valuation. At the time, it wasthe largest private funding round on record.\n\nAs part of itsAmazon partnership, OpenAI plans to develop a new “stateful runtime environment” where OpenAI models will run onAmazon’s Bedrock platform. The company will also expand itspreviously announced AWS partnership, which committed $38 billion in compute services, by $100 billion. OpenAI has committed to consuming at least 2GW of AWS Trainium compute as part of the deal, and also plans to build custom models to support Amazon consumer products.\n\n“We have lots of developers and companies eager to run services powered by OpenAI models on AWS,” said Amazon CEO Andy Jassy in a statement, “and our unique collaboration with OpenAI to provide stateful runtime environments will change what’s possible for customers building AI apps and agents.”\n\nThe Information hadpreviously reportedthat $35 billion of Amazon’s investment could be contingent on the company either achieving AGI or making its IPO by the end of the year. OpenAI’s announcement confirms the funding split, but says only that the additional $35 billion will arrive “in the coming months when certain conditions are met.”\n\nOpenAI gave fewer details on the Nvidia partnership, but said it had committed to using “3GW of dedicated inference capacity and 2GW of training on Vera Rubin systems” as part of the deal.\n\nNvidia’s participation in the round has been the subject of intense speculation, particularly as reports of a $100 billion investment in September gave way to reports of a smaller investment in the months that followed.\n\nIn January,Nvidia CEO Jensen Huang dismissed the idea that Nvidia was backing away from OpenAI, saying, “we will invest a great deal of money. I believe in OpenAI. The work that they do is incredible.”",
      "excerpt": "OpenAI has raised $110 billion in private funding, the companyannounced Friday morning, commencing one of the largest private funding rounds in history. The new funding consists of a $50 billion investment from Amazon as well as $30 billion each from Nvidia and SoftBank, against a $730 billion pre-m",
      "tags": [
        "Apple",
        "Amazon",
        "Cloud Computing",
        "EVs",
        "Google"
      ]
    },
    {
      "title": "Employees at Google and OpenAI support Anthropic’s Pentagon stand in open letter",
      "link": "https://techcrunch.com/2026/02/27/employees-at-google-and-openai-support-anthropics-pentagon-stand-in-open-letter/",
      "author": "Amanda Silberling",
      "date": "2026-02-27T08:23:58-08:00",
      "image": "https://techcrunch.com/wp-content/uploads/2023/09/53202070940_ea57312b1a_k.jpg?resize=1200,800",
      "category": "AI",
      "content": "Anthropic has reached a stalemate with the United States Department of War over the military’srequest for unrestricted accessto the AI company’s technology. But as the Pentagon’sFriday afternoon deadlinefor Anthropic’s compliance approaches, more than 300 Google employees and over 60 OpenAI employees have signedan open letterurging the leaders of their companies to support Anthropic and refuse this unilateral use.\n\nSpecifically, Anthropic stood in opposition to the use of AI for domestic mass surveillance and autonomous weaponry. The open letter’s signatories seek to encourage their employers to “put aside their differences and stand together” to uphold the boundaries Anthropic has asserted.\n\n“They’re trying to divide each company with fear that the other will give in,” the letter says. “That strategy only works if none of us know where the others stand.”\n\nThe letter specifically calls on executives at Google and OpenAI to maintain Anthropic’s red lines against mass surveillance and fully automated weaponry. “We hope our leaders will put aside their differences and stand together to continue to refuse the Department of War’s current demands.”\n\nLeaders at the companies have not yet formally reponded to the letter. TechCrunch has reached out to Google and OpenAI for comment.\n\nHowever, informal statements suggest both companies are sympathetic to Anthropic’s side of the case. In an interview with CNBC on Friday morning, OpenAI CEO Sam Altmansaidthat he doesn’t “personally think the Pentagon should be threatening DPA against these companies.” According to a CNN reporter, an OpenAI spokespersonconfirmedthat the company shares Anthropic’s red lines against autonomous weapons and mass surveillance.\n\nAgreed.  Mass surveillance violates the Fourth Amendment and has a chilling effect on freedom of expression. Surveillance systems are prone to misuse for political or discriminatory purposes.https://t.co/f2JRHAhjTW\n\nGoogle DeepMind has not formally addressed the conflict, but Chief Scientist Jeff Dean, presumably speaking as an individual, did express opposition to mass surveillance by the government.\n\n“Mass surveillance violates the Fourth Amendment and has a chilling effect on freedom of expression,” Deanwroteon X. “Surveillance systems are prone to misuse for political or discriminatory purposes.”\n\nAccording to anAxiosreport, the military currently can use X’s Grok, Google’s Gemini, and OpenAI’s ChatGPT for unclassified tasks, and has been negotiating with Google and OpenAI to bring its technology over for use in classified work.\n\nWhile Anthropic has an existing partnership with the Pentagon, the AI company has remained firm in maintaining the boundary that its AI be used for neither mass domestic surveillance, nor fully autonomous weaponry.\n\nDefense Secretary Pete Hegsethtold Anthropic CEO Dario Amodeithat if his company doesn’t concede, the Pentagon will either declare Anthropic a “supply chain risk” or invoke the Defense Production Act (DPA) to force the company to comply with military demands.\n\nIna statement on Thursday, Amodei maintained his company’s position. “These latter two threats are inherently contradictory: one labels us a security risk; the other labels Claude as essential to national security,” the statement reads. “Regardless, these threats do not change our position: we cannot in good conscience accede to their request.”",
      "excerpt": "Anthropic has reached a stalemate with the United States Department of War over the military’srequest for unrestricted accessto the AI company’s technology. But as the Pentagon’sFriday afternoon deadlinefor Anthropic’s compliance approaches, more than 300 Google employees and over 60 OpenAI employee",
      "tags": [
        "Apple",
        "Amazon",
        "Cloud Computing",
        "EVs",
        "Google"
      ]
    },
    {
      "title": "CISA replaces acting director after a bumbling year on the job",
      "link": "https://techcrunch.com/2026/02/27/cisa-replaces-acting-director-gottumukkala-after-a-bumbling-year-on-the-job/",
      "author": "Zack Whittaker",
      "date": "2026-02-27T07:57:02-08:00",
      "image": "https://techcrunch.com/wp-content/uploads/2026/02/gottumukkala-2260579973.jpg?resize=1200,915",
      "category": "Security",
      "content": "This week it was reported thatU.S. Cybersecurity and Infrastructure Security Agency is in dire shape, after a year of cuts, layoffs, and furloughs under the Trump administration. Now the agency has replaced its top acting leader, a CISA spokesperson tells TechCrunch.\n\nThe move to replace Madhu Gottumukkala as the acting director of CISA, an agency under the Department of Homeland Security that oversees cybersecurity and technical protection across the federal government, comes after a tumultuous year serving as the agency’s top boss.\n\nGottumukkala struggled to lead the agency during his tenure as acting director and causedsecurity headaches, including the uploading of sensitive government documents to ChatGPT, according to reports. Staffing at the agency wasslashed by one-third. Gottumukkala also reportedly failed acounterintelligence polygraphhe took in order to view classified documents, and suspended several career officials in response, including the agency’s then-chief security officer.\n\nBefore being nominated to CISA as deputy director, Gottumukkala was chief technology officer of South Dakota under then-governor and current Secretary of Homeland Security Kristi Noem.\n\nABC Newswas first to report Gottumukkala’s departure.\n\nIn a statement shared with TechCrunch on Friday, CISA spokesperson Marci McCarthy claimed Gottumukkala had done a “remarkable job.” McCarthy told TechCrunch that Nick Andersen will replace Gottumukkala as CISA’s new acting director, and that Gottumukkala has been moved to a new position as director of strategic implementation in the Department of Homeland Security, which houses CISA.\n\nPrior to his appointment as acting director to lead CISA, Andersenservedas the agency’s top official overseeing its cybersecurity division.\n\nThe agency still hasn’t had a permanent Senate-confirmed director since Trump returned to office.\n\nMcCarthy said the Trump administration has chosen Sean Plankey to be the agency’s permanent director, which requires a majority vote of approval in the U.S. Senate.\n\nThe White Housere-nominated Plankey to head CISA in January, after Sen. Ron Wyden last yearblocked Plankey’s nominationuntil the agency agreed to release an unclassified report allegedly describing cybersecurity flaws at phone and telecommunication giants. Wyden demanded the report’s releasein the wake of hundreds of hackstargeting U.S. and international phone and internet providers by the China-backed hacking group known as Salt Typhoon. The Senate has yet to schedule Plankey’s nomination hearing.\n\nNextgovreported Thursdaythat CISA lost another top senior official, Bob Costello, the agency’s chief information officer tasked with overseeing the agency’s IT systems and data policies. The news outlet reported Gottumukkala tried to transfer Costello but was blocked by unnamed political appointees.\n\nCISA’s spokesperson McCarthy did not address Costello’s departure when asked by TechCrunch, but did not dispute the report.",
      "excerpt": "This week it was reported thatU.S. Cybersecurity and Infrastructure Security Agency is in dire shape, after a year of cuts, layoffs, and furloughs under the Trump administration. Now the agency has replaced its top acting leader, a CISA spokesperson tells TechCrunch.\n\nThe move to replace Madhu Gottu",
      "tags": [
        "Apple",
        "Amazon",
        "Cloud Computing",
        "EVs",
        "Google"
      ]
    },
    {
      "title": "Apple and Netflix team up to air Formula 1 Canadian Grand Prix",
      "link": "https://techcrunch.com/2026/02/27/apple-and-netflix-team-up-to-air-formula-1-canadian-grand-prix/",
      "author": "Lauren Forristal",
      "date": "2026-02-27T09:17:18-08:00",
      "image": "https://techcrunch.com/wp-content/uploads/2026/02/Canada-race-F1-2026.jpeg?w=1200",
      "category": "Media & Entertainment",
      "content": "Apple and Netflix haveentered a partnershipto co-broadcast the Formula 1 Canadian Grand Prix, announced Thursday by Apple’s senior vice president of services, Eddy Cue. For the first time, F1 fans in the U.S. will be able to watch the live race simultaneously on both Apple TV and Netflix.\n\nNetflix subscribers will be able to stream the full race weekend — including practice, qualifying, and the Grand Prix itself on May 24 — live on the platform.\n\n​Beyond live race coverage, the partnership includes cross-promotion of Netflix’s hit series, “Drive to Survive.” For the first time, the eighth season — which consists of eight episodes covering the 2025 Formula One World Championship — will be available to both Apple TV subscribers in the U.S. and Netflix users globally, significantly broadening its audience.\n\nSeason 8 premieres today, on February 27.\n\nF1’s rise in American culture extends beyond television at this point — Brad Pitt’s “F1” is nominated for Best Picture at this year’s Academy Awards. “Drive to Survive” has successfullyattracted a diverse audiencefor its behind-the-scenes approach, transforming it from a typical sports docuseries into a compelling narrative that’s brought in millions of new fans.\n\nThe series has been a particular focus of Apple’s broader F1 ambitions: The company has said it plans to promote the sport across Apple News, Apple Maps (highlighting F1 tracks around the world), Apple Music, and Apple Fitness+, as well as in its physical retail stores.\n\nThis collaboration also means Netflix continues to push into live sports broadcasting, after pivoting from a“no-sports” stanceto securing major rights forNFL Christmas games,WWE Raw, andMLB.\n\nAdditionally, the joint effort comes as part of Apple’s newmulti-year dealwith Formula 1, under which Apple TV replaced ESPN as the exclusive U.S. broadcaster for all 24 races beginning this season. The deal is reportedly valued at around $150 million per season, a significant jump from the roughly$85 millionESPN reportedly paid. All races are available to Apple TV subscribers at no extra charge. The previous partnership with ESPN achieved an average viewership of1.3 millionin its final year.\n\nNotably,Netflixwas previously reported to be eyeing U.S. media rights for Formula 1 back in 2022.",
      "excerpt": "Apple and Netflix haveentered a partnershipto co-broadcast the Formula 1 Canadian Grand Prix, announced Thursday by Apple’s senior vice president of services, Eddy Cue. For the first time, F1 fans in the U.S. will be able to watch the live race simultaneously on both Apple TV and Netflix.\n\nNetflix s",
      "tags": [
        "Apple",
        "Amazon",
        "Cloud Computing",
        "EVs",
        "Google"
      ]
    },
    {
      "title": "ChatGPT reaches 900M weekly active users",
      "link": "https://techcrunch.com/2026/02/27/chatgpt-reaches-900m-weekly-active-users/",
      "author": "Aisha Malik",
      "date": "2026-02-27T10:25:51-08:00",
      "image": "https://techcrunch.com/wp-content/uploads/2025/02/GettyImages-2195918462.jpg?w=1024",
      "category": "",
      "content": "ChatGPT has reached 900 million weekly active users, OpenAIannouncedFriday, putting the AI chatbot within striking distance of 1 billion. OpenAI also shared that it now has 50 million paying subscribers.\n\n“Subscriber momentum accelerated meaningfully to start the year, with January and February on track to be the largest months for new subscribers in our history,” the company wrote in a blog post. “People use ChatGPT to learn, write, plan, and build. As usage scales, the product improves in ways people feel immediately: faster responses, higher reliability, stronger safety, and more consistent performance.”\n\nThe new weekly active user figure marks a jump of 100 million users from the800 millionthat OpenAI reported in October 2025.\n\nOpenAI shared the new numbers as part of its announcement that it hasraised $110 billionin private funding, marking one of the largest private funding rounds in history. The new funding includes a $50 billion investment from Amazon, along with $30 billion each from Nvidia and SoftBank, at a $730 billion pre-money valuation. The round remains open, and the company expects more investors to join.",
      "excerpt": "ChatGPT has reached 900 million weekly active users, OpenAIannouncedFriday, putting the AI chatbot within striking distance of 1 billion. OpenAI also shared that it now has 50 million paying subscribers.\n\n“Subscriber momentum accelerated meaningfully to start the year, with January and February on t",
      "tags": [
        "Apple",
        "Amazon",
        "Cloud Computing",
        "EVs",
        "Google"
      ]
    },
    {
      "title": "AI music generator Suno hits 2M paid subscribers and $300M in annual recurring revenue",
      "link": "https://techcrunch.com/2026/02/27/ai-music-generator-suno-hits-2-million-paid-subscribers-and-300m-in-annual-recurring-revenue/",
      "author": "Amanda Silberling",
      "date": "2026-02-27T09:22:02-08:00",
      "image": "https://techcrunch.com/wp-content/uploads/2025/06/GettyImages-2159558534.jpg?resize=1200,837",
      "category": "",
      "content": "Sunoco-founder and CEO Mikey Shulmanshared on LinkedInthat the AI music generator has amassed 2 million paid subscribers and $300 million in annual recurring revenue.\n\nJust three months ago, Suno announced a$250 million funding roundthat valued the company at $2.45 billion. At the time, Suno told The Wall Street Journal that annual revenue had hit $200 million — that would indicate that the company has had some major growth in a short time frame.\n\nSuno lets users create music using natural language prompts, making it possible for people with little experience to generate audio with little effort. This has sparked concern from musicians and record labels, who have sued Suno for copyright infringement, since its AI model was likely trained on existing recorded music. But Warner Music Group recentlysettled its lawsuitand instead reached a deal that allows Suno to launch models that use licensed music from its catalog.\n\nSuno has generated synthetic music that sounds real enough to top charts on Spotify and Billboard. Telisha Jones, a 31-year-old in Mississippi, used Suno to turn her poetry into the viral R&B song “How Was I Supposed to Know” and signed a record deal with Hallwood Media in a deal reportedly worth$3 million.\n\nStill, many musicians havespoken outagainst the use of AI in music, including Billie Eilish, Chappell Roan, Katy Perry, and more.",
      "excerpt": "Sunoco-founder and CEO Mikey Shulmanshared on LinkedInthat the AI music generator has amassed 2 million paid subscribers and $300 million in annual recurring revenue.\n\nJust three months ago, Suno announced a$250 million funding roundthat valued the company at $2.45 billion. At the time, Suno told Th",
      "tags": [
        "Apple",
        "Amazon",
        "Cloud Computing",
        "EVs",
        "Google"
      ]
    }
  ]
}