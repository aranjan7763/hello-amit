{
  "last_updated": "2026-02-28T06:42:38.103167+00:00",
  "articles": [
    {
      "title": "Pentagon moves to designate Anthropic as a supply-chain risk",
      "link": "https://techcrunch.com/2026/02/27/pentagon-moves-to-designate-anthropic-as-a-supply-chain-risk/",
      "author": "Russell Brandom",
      "date": "2026-02-27T13:53:14-08:00",
      "image": "https://techcrunch.com/wp-content/uploads/2025/07/GettyImages-2225249178.jpg?w=1024",
      "category": "AI",
      "content": "In a post on Truth Social, President Trump directed federal agencies to cease use of all Anthropic products after the company’spublic dispute with the Department of Defense. The president allowed for a six-month phase-out period for departments using the products, but emphasized that Anthropic was no longer welcome as a federal contractor.\n\n“We don’t need it, we don’t want it, and will not do business with them again,” the president wrote in the post.\n\npic.twitter.com/B51SWfn81N\n\nNotably, the president’s post did not mention any plans to designate Anthropic as a supply chain risk, as had been previously mentioned as a consequence. However,a subsequent tweetfrom Secretary of Defense Pete Hegseth made good on the threat.\n\n“In conjunction with the President’s directive for the Federal Government to cease all use of Anthropic’s technology, I am directing the Department of War to designate Anthropic a Supply-Chain Risk to National Security,” Secretary Hegseth wrote. “Effective immediately, no contractor, supplier, or partner that does business with the United States military may conduct any commercial activity with Anthropic.”\n\nThe Pentagon dispute centered on Anthropic’s refusal to allow its AI models to be used to power either mass domestic surveillance or fully autonomous weapons, which Secretary Hegseth found unduly restrictive.\n\nCEO Dario Amodei reiterated his stancein a public post on Thursday, refusing to compromise on the two points.\n\n“Our strong preference is to continue to serve the Department and our warfighters — with our two requested safeguards in place,” Amodei wrote at the time. “Should the Department choose to offboard Anthropic, we will work to enable a smooth transition to another provider, avoiding any disruption to ongoing military planning, operations, or other critical missions.”\n\nOpenAI reportedly came out in support of Anthropic’s decision.Per the BBC, CEO Sam Altman sent a memo to staff on Thursday saying he shared the same “red lines” and that any OpenAI-related defense contracts would also reject uses that were “unlawful or unsuited to cloud deployments, such as domestic surveillance and autonomous offensive weapons.”\n\nOpenAI co-founder Ilya Sutskever, who very publicly fell out with Altman inNovember 2023and has since co-founded his own AI company, also waded into the conversation on Friday,writing on X: “It’s extremely good that Anthropic has not backed down, and it’s significant that OpenAI has taken a similar stance.\n\nIn the future, there will be much more challenging situations of this nature, and it will be critical for the relevant leaders to rise up to the occasion, for fierce competitors to put their differences aside. Good to see that happen today.”\n\nBut within hours of the Trump administration ordering federal agencies to cut ties with Anthropic, OpenAI moved to fill the void, announcing a deal with the Pentagon that Altman said preserved the same core principles Anthropic had fought for — prohibitions on domestic surveillance and autonomous weapons. According to the New York Times, OpenAI and the government began meeting about a potential tie-up on Wednesday of this week.\n\nSurely, there will be more twists to come.\n\nAnthropic, OpenAI and Google each receivedcontract awardsfrom the U.S. Defense Department last July. While someGoogle employeeshave come out in support of Anthropic, Google and its parent company have yet to comment.\n\nUpdate: This story has been updated with additional reporting.",
      "excerpt": "In a post on Truth Social, President Trump directed federal agencies to cease use of all Anthropic products after the company’spublic dispute with the Department of Defense. The president allowed for a six-month phase-out period for departments using the products, but emphasized that Anthropic was n",
      "tags": [
        "Apple",
        "Amazon",
        "Cloud Computing",
        "EVs",
        "Google"
      ]
    },
    {
      "title": "Musk bashes OpenAI in deposition, saying ‘nobody committed suicide because of Grok’",
      "link": "https://techcrunch.com/2026/02/27/musk-bashes-openai-in-deposition-saying-nobody-committed-suicide-because-of-grok/",
      "author": "Sarah Perez",
      "date": "2026-02-27T11:42:00-08:00",
      "image": "https://techcrunch.com/wp-content/uploads/2024/11/GettyImages-2183887189.jpg?resize=1200,800",
      "category": "AI",
      "content": "In a newly released deposition filed in Elon Musk’s case against OpenAI, the tech executive attacked OpenAI’s safety record, claiming that his company, xAI, better prioritizes safety.  He went so far as to say that “Nobody has committed suicide because of Grok, but apparently they have because of ChatGPT.”\n\nThe comment came up in a line of questioning about apublic letterMusk signed in March 2023. In it, he called on AI labs to pause development of AI systems more powerful than GPT-4, OpenAI’s flagship model at the time, for at least six months. The letter, which was signed by over 1,100 people, including many AI experts, stated there was not enough planning and management taking place at AI labs, as they were locked in an “out-of-control race to develop and deploy ever more powerful digital minds that no one — not even their creators — can understand, predict, or reliably control.”\n\nThose fears have since gained credibility. OpenAI now faces aseries of lawsuitsalleging thatChatGPT’s manipulative conversation tacticshave led several people to experience negative mental health effects, with some dying by suicide. Musk’s comment suggests that these incidents could be used as fodder in his case against OpenAI.\n\nThe transcript of Musk’s video testimony, which took place back in September, was filed publicly this week, ahead of the expected jury trial next month.\n\nThelawsuitagainst OpenAI centers on the company’s shift from a nonprofit AI research lab to a for-profit company, whichMusk claims violatedits founding agreements. As part of his arguments, Musk claims that AI safety could be compromised by OpenAI’s commercial relationships, as such relationships would place speed, scale, and revenue above safety concerns.\n\nHowever, since that recording, xAI has faced safety concerns of its own. Last month, Musk’s social network X wasflooded with nonconsensual nude imagesgenerated by xAI’s Grok, some of whichwere said to be of minors. This led the California Attorney General’s office toopen an investigationinto the matter. The EU is alsorunning its own investigation, and other governments have taken action, too, with some imposing blocks and bans.\n\nIn the newly filed deposition, Musk claimed he had signed the AI safety letter because “it seemed like a good idea,” not because he had just incorporated an AI company looking to compete with OpenAI.\n\n“I signed it, as many people did, to urge caution with AI development,” Musk said. “I just wanted … AI safety to be prioritized.”\n\nMusk also responded to other questions in the deposition, including those about artificial general intelligence, or AGI — the concept of AI that can match or surpass human reasoning across a broad range of tasks — saying “it has a risk.” He also confirmed that he “was mistaken” about hissupposed $100 million donationto OpenAI; thesecond amended complaintin the case puts the actual figure closer to $44.8 million.\n\nHe also recalled why OpenAI was founded, which, from his perspective, was because he was “increasingly concerned about the danger of Google being a monopoly in AI,” adding that his conversations with Google co-founder Larry Page were “alarming, in that he did not seem to be taking AI safety seriously.” OpenAI was formed as a counterweight to that threat, Musk claimed.",
      "excerpt": "In a newly released deposition filed in Elon Musk’s case against OpenAI, the tech executive attacked OpenAI’s safety record, claiming that his company, xAI, better prioritizes safety.  He went so far as to say that “Nobody has committed suicide because of Grok, but apparently they have because of Ch",
      "tags": [
        "Apple",
        "Amazon",
        "Cloud Computing",
        "EVs",
        "Google"
      ]
    },
    {
      "title": "Perplexity’s new Computer is another bet that users need many AI models",
      "link": "https://techcrunch.com/2026/02/27/perplexitys-new-computer-is-another-bet-that-users-need-many-ai-models/",
      "author": "Tim Fernholz",
      "date": "2026-02-27T09:00:55-08:00",
      "image": "https://techcrunch.com/wp-content/uploads/2025/01/GettyImages-2181313521.jpg?w=1024",
      "category": "AI",
      "content": "Starting this week, Perplexity subscribers will have a new agentic tool at their disposal.\n\nPerplexity Computer, in the company’s words, “unifies every current AI capability into a single system.” More specifically, Perplexity says it is a computer user agent that can execute complex workflows independently using 19 different AI models, even creating subagents to handle specific problems.\n\nThe tool is available now, only on the company’s highest subscription tier, the $200/month Perplexity Max. It runs entirely in the cloud, which might spare it some of the security concerns of other agentic tools like OpenClaw.\n\nTechCrunch hasn’t done a hands-on demo of the new tool, but inexample workflowson Perplexity’s website, it is shown handling tasks that involve collecting statistics, financial, or legal data; creating analysis; and sharing its findings as finished websites or visualizations.\n\nPerplexity invited the press to a background briefing with executives last week to discuss the product and lay out the agenda for the year. The event was intended to include a demonstration of the tool, but the company canceled the demo because of flaws found in the product hours before the event.\n\nThis tool represents the evolution of Perplexity, which made a splash early in the AI boom by wrapping frontier models in familiar user interfaces, particularly its search-engine-like answer service. It then moved on to launch its Comet web browser last summer. Competitors like Google have now changed their products to be more like those built at Perplexity, one executive said, but that’s a threat as much as a compliment.\n\nThe company is changing in response to a shifting ecosystem: One of the first AI companies to offer advertising, it abandoned that business late last year, saying last week that it undermined users’ trust in their answers’ accuracy. But Perplexity’s total user base — in the tens of millions of users — pales in comparison to that of OpenAI, which claims 800 million weekly users and began testing ads in ChatGPT this year.\n\nNow, Perplexity executives say they are aiming for a more boutique set of users, with products that serve people making “GDP-moving decisions.” Executives in the briefing, who asked not to be identified by name, described prioritizing enterprise subscriptions, particularly for deep research.\n\n“You don’t hear us talk about MAUs ever, because we’re not actually on a mission to get as many users as possible,” one executive said.\n\nPerplexity recently released a new benchmark for complex research tasks, called Draco, where (no surprise) its own deep research offering beats out competitors like Gemini.\n\nPerplexity says it is no longer reliant on other companies’ APIs for its web index and now has its own AI-optimized search API. But the company is doubling down on packaging frontier models in a consumer-friendly user experience, arguing that there is value in orchestrating multiple third-party LLMs to obtain the most cost-effective and accurate answers to queries.\n\n“Multi-model is the future,” one Perplexity exec argued. Models, in their view, are specializing, not commoditizing. The company has found that its users frequently switch between models to obtain the results they are looking for, with December 2025 queries for visual outputs most often sent to Gemini Flash, software engineering done in Claude Sonnet 4.5, and medical research in GPT-5.1.\n\nIf one LLM is better at coding tasks and another does a better job drafting marketing copy, Perplexity’s software can automatically choose the ideal one. Another example, executives said, is running Perplexity’s own modified open source Chinese-built LLMs to answer queries more cheaply, a technique the company got dinged for hiding from its customers last year. But done transparently, the technique could prove an efficient way to optimize LLM queries.\n\nThe company also offers users the opportunity to query multiple models at once, in a feature called Model Council. But the unit economics of offering multiple queries at flat subscription rates aren’t entirely clear.\n\nStill, without expensive infrastructure projects on its books and with, the executives claimed, high margins on user fees, Perplexity believes it will remain competitive by allocating tokens to the best model for a purpose.\n\nAnd there is more on the horizon: Perplexity Comet browser is coming to iOS next month, and the company is planning a developers conference, Ask, on March 11 in San Francisco to promote third-party use of its API.\n\nOne executive said that instead of looking at the previous day’s number of queries each morning, he was now looking at the most recent revenue metrics. At least some customers are noticing a new focus on the bottom line, with the Perplexity subreddit featuring frequent complaints of new rate limits on free and subscription product tiers.\n\nHowever, the execs at the briefing dismiss such complaints: “Any discussions on the free tier being made worse or rate-limited is completely false,” one said.",
      "excerpt": "Starting this week, Perplexity subscribers will have a new agentic tool at their disposal.\n\nPerplexity Computer, in the company’s words, “unifies every current AI capability into a single system.” More specifically, Perplexity says it is a computer user agent that can execute complex workflows indep",
      "tags": [
        "Apple",
        "Amazon",
        "Cloud Computing",
        "EVs",
        "Google"
      ]
    },
    {
      "title": "Anthropic vs. the Pentagon: What’s actually at stake?",
      "link": "https://techcrunch.com/2026/02/27/anthropic-vs-the-pentagon-whats-actually-at-stake/",
      "author": "Rebecca Bellan",
      "date": "2026-02-27T11:11:04-08:00",
      "image": "https://techcrunch.com/wp-content/uploads/2026/02/GettyImages-2218106494.jpg?resize=1200,800",
      "category": "Government & Policy",
      "content": "The past two weeks have been defined by aclashbetween Anthropic CEO Dario Amodei and Defense Secretary Pete Hegseth as the two battle over the military’s use of AI.\n\nAnthropic refuses to allow its AI models to be used for mass surveillance of Americans or for fully autonomous weapons that conduct strikes without human input. At the same time, Secretary Hegseth has argued the Department of Defense shouldn’t be limited by the rules of a vendor, arguing any “lawful use” of the technology should be permitted.\n\nOn Thursday,Amodei publicly signaledthat Anthropic isn’t backing down — despite threats that his company could be designated as a supply chain risk as a result. But with the news cycle moving fast, it’s worth revisiting exactly what’s at stake in the fight.\n\nAt its core, this fight is about who controls powerful AI systems — the companies that build them, or the government that wants to deploy them.\n\nAs we said above, Anthropic doesn’t want its AI models to be used for mass surveillance of Americans or for autonomous weapons with no humans in the loop for targeting and firing decisions. Traditional defense contractors typically have little say in how their products will be used, but Anthropic has argued from its inception that AI technology poses unique risks and therefore requires unique safeguards. From the company’s perspective, the question is how to maintain those safeguards when the technology is being used by the military.\n\nThe U.S. military already relies on highly automated systems, some of which are lethal. The decision to use lethal force has historically been left to humans, but there are few legal restrictions on military use of autonomous weapons. The DoD doesn’t categorically ban fully autonomous weapons systems. According to a2023 DOD directive, AI systems can select and engage targets without human intervention, as long as they meet certain standards and pass review by senior defense officials.\n\nThat’s precisely what makes Anthropic nervous. Military technology is secretive by nature, so if the U.S. military were taking steps to automate lethal decision-making, we might not know about it until it was operational. And if it used Anthropic’s models, it could count as “lawful use.”\n\nAnthropic’s position isn’t that such uses should be permanently off the table. It’s that its models aren’t capable enough to support them safely yet. Imagine an autonomous system misidentifying a target, escalating a conflict without human authorization, or making a split-second lethal decision that no one can reverse. Put a less-capable AI in charge of weapons, and you get a very fast, very confident machine that’s bad at making high-stakes calls.\n\nAI also has the power to supercharge lawful surveillance of American citizens to a concerning degree. Under current U.S. laws, surveillance of American citizens is already possible, whether through collection of texts, emails, and other communication. AI changes the equation by enabling automated large-scale pattern detection, entity resolution across datasets, predictive risk scoring, and continuous behavioral analysis.\n\nThe Pentagon’s argument is that it should be able to deploy Anthropic’s technology for any lawful use it deems necessary, rather than be limited by Anthropic’s internal policies on things like autonomous weapons or surveillance.\n\nMore specifically, Secretary Hegseth has argued the Department of Defense shouldn’t be limited by the rules of a vendor and that it would engage in “lawful use” of the technology.\n\nSean Parnell, the Pentagon’s chief spokesperson, said in aThursday X postthat the department has no interest in conducting mass domestic surveillance or deploying autonomous weapons.\n\n“Here’s what we’re asking: Allow the Pentagon to use Anthropic’s model for all lawful purposes,” Parnell said. “This is a simple, common-sense request that will prevent Anthropic from jeopardizing critical military operations and potentially putting our warfighters at risk. We will not let ANY company dictate the terms regarding how we make operational decisions.”\n\nHe added that Anthropic has until 5:01 p.m. ET on Friday to decide. “Otherwise, we will terminate our partnership with Anthropic and deem them a supply chain risk for DOW,” he said.\n\nDespite the DoD’s stance that it simply doesn’t believe it should be limited by a corporation’s usage policies, Secretary Hegseth’s concerns about Anthropic have at times seemed connected to cultural grievance. Ina speech at SpaceX and xAI offices in January, Hegseth railed against “woke AI” in a speech that some saw as a preview of his feud with Anthropic.\n\n“Department of War AI will not be woke,” Hegseth said. “We’re building war-ready weapons and systems, not chatbots for an Ivy League faculty lounge.”\n\nThe Pentagon has threatened to either declare Anthropic a “supply chain risk” — which effectively blacklists Anthropic from doing business with the government — or invoke the Defense Production Act (DPA) to force the company to tailor its model to the military’s needs. Hegseth has given Anthropic until 5:01 p.m. on Friday to respond. But with the deadline approaching, it’s anyone’s guess whether the Pentagon will make good on its threat.\n\nThis is not a fight either party can easily walk away from. Sachin Seth, a VC at Trousdale Ventures who focuses on defense tech, says a supply chain risk label for Anthropic could mean “lights out” for the company.\n\nHowever, he said, if Anthropic is dropped from the DoD, it could be a national security issue.\n\n“[The Department] would have to wait six to 12 months for either OpenAI or xAI to catch up,” Seth told TechCrunch. “That leaves a window of up to a year where they might be working from not the best model, but the second or third best.”\n\nxAI is gearing up to become classified-ready and replace Anthropic, and it’s fair to say given ownerElon Musk’s rhetoricon the matter that the company would have no problem giving the DoD total control over its technology. Recentreportsindicate that OpenAI may stick to the same red lines as Anthropic.",
      "excerpt": "The past two weeks have been defined by aclashbetween Anthropic CEO Dario Amodei and Defense Secretary Pete Hegseth as the two battle over the military’s use of AI.\n\nAnthropic refuses to allow its AI models to be used for mass surveillance of Americans or for fully autonomous weapons that conduct st",
      "tags": [
        "Apple",
        "Amazon",
        "Cloud Computing",
        "EVs",
        "Google"
      ]
    },
    {
      "title": "OpenAI fires employee for using confidential info on prediction markets",
      "link": "https://techcrunch.com/2026/02/27/openai-fires-employee-for-using-confidential-info-on-prediction-markets/",
      "author": "Julie Bort",
      "date": "2026-02-27T15:00:54-08:00",
      "image": "https://techcrunch.com/wp-content/uploads/2023/06/OpenAI-logo-symmetry.jpg?resize=1200,675",
      "category": "",
      "content": "OpenAI has fired an employee over the employee’s activity on prediction markets, including Polymarket, the companyconfirmed to Wired.The employee used confidential OpenAI information in connection with the trades made, the company alleges.\n\nOpenAI didn’t release the name of the employee. However, a spokesperson said that such actions violated a company policy that bans workers from using inside information for personal gain, including on prediction markets.\n\nPrediction markets like Polymarket and Kalshi allow people to make wagers on the outcomes of real-world events. For instance, on Polymarket, there are wagers being made around the kind of products OpenAI will announce in 2026 and when the company will go public. They can cover any event, and some eye-popping money can be made. As we recently reported,an accountant won a $470,300 jackpot on Kalshiby betting against DOGE believers.\n\nPrediction markets insist they are not gambling sites, preferring to label themselves as financial platforms. Kalshi is a regulated exchange and, in fact, itfined and banned a MrBeast editor for similar alleged insider tradingearlier this week. OpenAI did not immediately respond to a request for additional comment.",
      "excerpt": "OpenAI has fired an employee over the employee’s activity on prediction markets, including Polymarket, the companyconfirmed to Wired.The employee used confidential OpenAI information in connection with the trades made, the company alleges.\n\nOpenAI didn’t release the name of the employee. However, a ",
      "tags": [
        "Apple",
        "Amazon",
        "Cloud Computing",
        "EVs",
        "Google"
      ]
    },
    {
      "title": "Ultrahuman bets on redesigned smart ring to win back US market after Oura dispute",
      "link": "https://techcrunch.com/2026/02/27/ultrahuman-unveils-new-smart-ring-as-it-awaits-u-s-clearance-after-oura-dispute/",
      "author": "Jagmeet Singh",
      "date": "2026-02-27T03:00:00-08:00",
      "image": "https://techcrunch.com/wp-content/uploads/2026/02/ultrahuman-ring-pro.jpg?resize=1200,800",
      "category": "Biotech & Health",
      "content": "Ultrahuman on Friday unveiled a new smart ring with longer battery life and a redesigned form factor, as the Bengaluru-based wearable maker seeks to revive its U.S. business that was disrupted last year by a patent dispute with rival Oura.\n\nThe Ring Pro, Ultrahuman’s third-generation smart ring, offers up to 15 days of battery life — compared with four to six days on theRing Air— and is priced at $479. It will be available for preorders globally, excluding the U.S., with shipments beginning in March.\n\nUltrahuman’s U.S. business was disrupted in October 2025 after the U.S. International Trade Commission — a federal agency that handles trade disputes —ruled in Oura’s favorin a patent dispute. The ruling prevented the startup from importing new ring inventory into the country, although existing retail stock continued to be sold. The blow was significant. The U.S. accounted for about 45% of Ultrahuman’s roughly 700,000 daily active users worldwide, according to co-founder and CEO Mohit Kumar.\n\nIn August 2025, Ultrahuman alsofiled a separate patent infringement caseagainst Oura in the Delhi High Court, where the matter remains pending.\n\nMeanwhile, to work around Oura’s patent, Ultrahuman developed the Ring Pro with a new design, Kumar told TechCrunch, adding that the device has been submitted to the U.S. Customs and Border Protection for clearance to confirm it can legally be imported into the country.\n\nDespite the U.S. disruption, Ultrahuman is currently operating at an annualized revenue run rate of about $150 million, Kumar said. Itreported $64 millionin operating revenue in the financial year ended March 2025. The startup remains profitable after tax, although margins are expected to narrow due to litigation costs, tariffs, and the redesign effort, he added.\n\nAlongside the new ring, Ultrahuman introduced Jade, a real-time “biointelligence” system that analyzes user health data across its devices and services to generate personalized insights and recommendations.\n\nKumar said Jade is designed to move beyond retrospective health summaries toward real-time, actionable guidance.\n\n“Most AI tools today look backward at your data,” he said. “Jade is built to react to your health in real time and surface actions users can take.”\n\nKumar said Jade will be available to all Ultrahuman users, including those using the older Ring Air, and does not currently require a subscription.\n\nThe Ring Pro features a redesigned heart-rate sensing architecture for improved signal quality during sleep and a new dual-core processor to enhance data accuracy and on-device computing. The device can store up to 250 days of health data and weighs about 5% to 6% more than the Ring Air, launched in July 2023 at $349.\n\nUltrahuman has also introduced a Pro Charger with up to 45 days of battery life to support on-the-go charging and enable faster updates and diagnostics through direct case connectivity. The charger also supports wireless charging via Qi, the same standard used by most modern smartphones.\n\nWomen account for about 68% of Ultrahuman’s user base, up from roughly 65% a year earlier, Kumar said, reflecting strong adoption of the startup’s women’s health features.\n\nUltrahuman also offers subscription-based services across its broader health platform, including a coaching and recovery program called PowerPlugs, the Blood Vision metabolic panel, Ultrahuman Home, and a continuous glucose monitoring offering. Subscriptions contribute about 16% of Ultrahuman’s revenue, while Blood Vision accounts for roughly 5% to 6% of the business, Kumar said.\n\nUltrahuman’s key growth markets include the U.K., Canada, Australia, and India, Kumar told TechCrunch, with the latter contributing about 8% to 9% of overall revenue after recent investments in local customer support.\n\nGlobal smart ring shipments grew nearly 80% year-over-year in 2025, driven by demand for compact wearables with advanced sleep tracking and longer battery life, said Anshika Jain, senior analyst at Counterpoint Research. Oura continues to lead with more than two-thirds of the market, while Ultrahuman holds the second position.\n\nJain added that future leaders in the category will be defined by sensor accuracy, AI-driven insights, and seamless ecosystem integration.\n\nSeparate IDC data showed global smart ring shipments rising about 30% year over year in Q3 2025 to nearly 1 million units, driven in part by demand for screenless fitness trackers, said Navkendar Singh, associate vice president at IDC India. Ultrahuman captured roughly 25% of the market during the period, per IDC.\n\nFounded in 2019, Ultrahuman has raised about $55 million to date and counts Alpha Wave Incubation, Blume Ventures, Steadview Capital, and Nexus Venture Partners among its investors.\n\nUltrahuman, Kumar said, is building additional production capacity to support demand for the Ring Pro over the coming months.",
      "excerpt": "Ultrahuman on Friday unveiled a new smart ring with longer battery life and a redesigned form factor, as the Bengaluru-based wearable maker seeks to revive its U.S. business that was disrupted last year by a patent dispute with rival Oura.\n\nThe Ring Pro, Ultrahuman’s third-generation smart ring, off",
      "tags": [
        "Apple",
        "Amazon",
        "Cloud Computing",
        "EVs",
        "Google"
      ]
    },
    {
      "title": "OpenAI raises $110B in one of the largest private funding rounds in history",
      "link": "https://techcrunch.com/2026/02/27/openai-raises-110b-in-one-of-the-largest-private-funding-rounds-in-history/",
      "author": "Russell Brandom",
      "date": "2026-02-27T06:13:01-08:00",
      "image": "https://techcrunch.com/wp-content/uploads/2025/04/GettyImages-2197366846.jpg?resize=1200,800",
      "category": "AI",
      "content": "OpenAI has raised $110 billion in private funding, the companyannounced Friday morning, commencing one of the largest private funding rounds in history. The new funding consists of a $50 billion investment from Amazon as well as $30 billion each from Nvidia and SoftBank, against a $730 billion pre-money valuation.\n\nNotably, the round remains open, and OpenAI expects more investors to join as it proceeds.\n\n“We are entering a new phase where frontier AI moves from research into daily use at global scale,” OpenAI said. “Leadership will be defined by who can scale infrastructure fast enough to meet demand, and turn that capacity into products people rely on.”\n\nAs part of the investment, OpenAI is launching significant infrastructure partnerships with both Amazon and Nvidia. As in previous rounds, it is likely that a significant portion of the dollar amount comes in the form of services rather than cash, although the precise split was not disclosed.\n\nThe company’s previous round closed in March 2025, raising $40 billion against a $300 billion valuation. At the time, it wasthe largest private funding round on record.\n\nAs part of itsAmazon partnership, OpenAI plans to develop a new “stateful runtime environment” where OpenAI models will run onAmazon’s Bedrock platform. The company will also expand itspreviously announced AWS partnership, which committed $38 billion in compute services, by $100 billion. OpenAI has committed to consuming at least 2GW of AWS Trainium compute as part of the deal, and also plans to build custom models to support Amazon consumer products.\n\n“We have lots of developers and companies eager to run services powered by OpenAI models on AWS,” said Amazon CEO Andy Jassy in a statement, “and our unique collaboration with OpenAI to provide stateful runtime environments will change what’s possible for customers building AI apps and agents.”\n\nThe Information hadpreviously reportedthat $35 billion of Amazon’s investment could be contingent on the company either achieving AGI or making its IPO by the end of the year. OpenAI’s announcement confirms the funding split, but says only that the additional $35 billion will arrive “in the coming months when certain conditions are met.”\n\nOpenAI gave fewer details on the Nvidia partnership, but said it had committed to using “3GW of dedicated inference capacity and 2GW of training on Vera Rubin systems” as part of the deal.\n\nNvidia’s participation in the round has been the subject of intense speculation, particularly as reports of a $100 billion investment in September gave way to reports of a smaller investment in the months that followed.\n\nIn January,Nvidia CEO Jensen Huang dismissed the idea that Nvidia was backing away from OpenAI, saying, “we will invest a great deal of money. I believe in OpenAI. The work that they do is incredible.”",
      "excerpt": "OpenAI has raised $110 billion in private funding, the companyannounced Friday morning, commencing one of the largest private funding rounds in history. The new funding consists of a $50 billion investment from Amazon as well as $30 billion each from Nvidia and SoftBank, against a $730 billion pre-m",
      "tags": [
        "Apple",
        "Amazon",
        "Cloud Computing",
        "EVs",
        "Google"
      ]
    },
    {
      "title": "Employees at Google and OpenAI support Anthropic’s Pentagon stand in open letter",
      "link": "https://techcrunch.com/2026/02/27/employees-at-google-and-openai-support-anthropics-pentagon-stand-in-open-letter/",
      "author": "Amanda Silberling",
      "date": "2026-02-27T08:23:58-08:00",
      "image": "https://techcrunch.com/wp-content/uploads/2023/09/53202070940_ea57312b1a_k.jpg?resize=1200,800",
      "category": "AI",
      "content": "Anthropic has reached a stalemate with the United States Department of War over the military’srequest for unrestricted accessto the AI company’s technology. But as the Pentagon’sFriday afternoon deadlinefor Anthropic’s compliance approaches, more than 300 Google employees and over 60 OpenAI employees have signedan open letterurging the leaders of their companies to support Anthropic and refuse this unilateral use.\n\nSpecifically, Anthropic stood in opposition to the use of AI for domestic mass surveillance and autonomous weaponry. The open letter’s signatories seek to encourage their employers to “put aside their differences and stand together” to uphold the boundaries Anthropic has asserted.\n\n“They’re trying to divide each company with fear that the other will give in,” the letter says. “That strategy only works if none of us know where the others stand.”\n\nThe letter specifically calls on executives at Google and OpenAI to maintain Anthropic’s red lines against mass surveillance and fully automated weaponry. “We hope our leaders will put aside their differences and stand together to continue to refuse the Department of War’s current demands.”\n\nLeaders at the companies have not yet formally reponded to the letter. TechCrunch has reached out to Google and OpenAI for comment.\n\nHowever, informal statements suggest both companies are sympathetic to Anthropic’s side of the case. In an interview with CNBC on Friday morning, OpenAI CEO Sam Altmansaidthat he doesn’t “personally think the Pentagon should be threatening DPA against these companies.” According to a CNN reporter, an OpenAI spokespersonconfirmedthat the company shares Anthropic’s red lines against autonomous weapons and mass surveillance.\n\nAgreed.  Mass surveillance violates the Fourth Amendment and has a chilling effect on freedom of expression. Surveillance systems are prone to misuse for political or discriminatory purposes.https://t.co/f2JRHAhjTW\n\nGoogle DeepMind has not formally addressed the conflict, but Chief Scientist Jeff Dean, presumably speaking as an individual, did express opposition to mass surveillance by the government.\n\n“Mass surveillance violates the Fourth Amendment and has a chilling effect on freedom of expression,” Deanwroteon X. “Surveillance systems are prone to misuse for political or discriminatory purposes.”\n\nAccording to anAxiosreport, the military currently can use X’s Grok, Google’s Gemini, and OpenAI’s ChatGPT for unclassified tasks, and has been negotiating with Google and OpenAI to bring its technology over for use in classified work.\n\nWhile Anthropic has an existing partnership with the Pentagon, the AI company has remained firm in maintaining the boundary that its AI be used for neither mass domestic surveillance, nor fully autonomous weaponry.\n\nDefense Secretary Pete Hegsethtold Anthropic CEO Dario Amodeithat if his company doesn’t concede, the Pentagon will either declare Anthropic a “supply chain risk” or invoke the Defense Production Act (DPA) to force the company to comply with military demands.\n\nIna statement on Thursday, Amodei maintained his company’s position. “These latter two threats are inherently contradictory: one labels us a security risk; the other labels Claude as essential to national security,” the statement reads. “Regardless, these threats do not change our position: we cannot in good conscience accede to their request.”",
      "excerpt": "Anthropic has reached a stalemate with the United States Department of War over the military’srequest for unrestricted accessto the AI company’s technology. But as the Pentagon’sFriday afternoon deadlinefor Anthropic’s compliance approaches, more than 300 Google employees and over 60 OpenAI employee",
      "tags": [
        "Apple",
        "Amazon",
        "Cloud Computing",
        "EVs",
        "Google"
      ]
    },
    {
      "title": "India disrupts access to popular developer platform Supabase with blocking order",
      "link": "https://techcrunch.com/2026/02/27/india-disrupts-access-to-popular-developer-platform-supabase-with-blocking-order/",
      "author": "Jagmeet Singh",
      "date": "2026-02-27T19:51:52-08:00",
      "image": "https://techcrunch.com/wp-content/uploads/2026/02/supabase.jpg?resize=1200,800",
      "category": "Government & Policy",
      "content": "Supabase, a popular developer database platform, is facing disruptions in India — one of its key markets — has been blocked in India, TechCrunch has learned. New Delhi ordered internet providers to block its website, resulting in patchy access across networks.\n\nThe blocking order was issued on February 24 under Section 69A of India’s Information Technology Act, according to a source familiar with the matter. The provision empowers the government to restrict public access to online content.\n\nThe Indian government did not publicly cite a reason for the move, and it was not immediately clear whether the action was linked to a cybersecurity concern, copyright complaint, or another issue. It was also unclear how long the restrictions would remain in place.\n\nAccess to Supabase has been inconsistent in India over the past several days, with the San Francisco-based companyacknowledging the issuein posts on social media starting Wednesday. While the restrictions were first reported by Supabase on Reliance Industries’ JioFiber network, users have since flagged similar problems across multiple internet providers and telecom networks. In one post on Friday, Supabase tagged India’s IT minister Ashwini Vaishnaw, asking him to intervene and restore access, though the company later removed the message and said in a subsequent update that the site remained blocked for many users in the country.\n\nWe understand many users in India continue to be blocked from accessing Supabase. We acknowledge the difficulties this is causing for our users there. Supabase continues to follow up through all available channels to resolve this issue.We continue to advise affected customers…\n\nAn Indian founder, who asked not to be named to avoid potential repercussions, told TechCrunch they had stopped seeing new user sign-ups from India over the past two to three days. A technology consultant working with local startups, who spoke on condition of anonymity, said they were unable to reliably access Supabase for both development and production purposes.\n\nWhile Supabase suggested workarounds such as switching DNS settings or using a VPN (which reroute internet traffic to bypass local restrictions), the founder said such steps were not practical for most end users.\n\nAt the time of publication, TechCrunch was able to verify that supabase.co remained inaccessible on ACT Fibernet, JioFiber and Airtel connections in New Delhi. However, two users on ACT Fibernet in Bengaluru said they were still able to access the service, suggesting the restrictions may be unevenly implemented.\n\nNotably, Supabase’smain websiteremained accessible in India — but its underlying developer infrastructure did not.\n\nIndia is Supabase’s fourth-largest source of traffic, accounting for about 9% of global visits, according to data from Similarweb, highlighting the potential fallout for the country’s developer ecosystem. The platform’s global traffic jumped more than 111% year over year to about 4.2 million visits in January. In India, visits rose roughly 179% to about 365,000, compared with a 168.5% increase in the U.S. to about 627,000.\n\nThe incident highlights broader concerns about India’s website blocking regime, said Raman Jit Singh Chima, Asia Pacific policy director at Access Now.\n\n“This is a simple fact that has grave consequences for developers and others,” he told TechCrunch. “You don’t know where you can safely run projects without the danger that something might happen where it gets blocked, and suddenly you’re scrambling to find a way.”\n\nIndia has previously faced criticism over broad website blocking measures. In 2014, authorities briefly restrictedaccess to developer platform GitHub, along with services such as Vimeo, Pastebin and Weebly, during a security probe. Users on some Indian networks in 2023 alsoreportedthat a key GitHub content domain had been blocked by certain ISPs, according to earlier reports.\n\nFounded in 2020 by CEO Paul Copplestone and CTO Ant Wilson, Supabase positions itself as an open-source alternative to Firebase built on PostgreSQL. The startup hasgained tractionamid rising interest in so-called “vibe coding” tools and AI-driven app development, and has raised about $380 million across three funding rounds since September 2024, lifting itsvaluation to $5 billion.\n\nIndia’s Ministry of Electronics and IT, as well as telecom providers including ACT Fibernet, Bharti Airtel, and Reliance Jio, did not respond to requests for comment. Copplestone and Wilson also did not respond.",
      "excerpt": "Supabase, a popular developer database platform, is facing disruptions in India — one of its key markets — has been blocked in India, TechCrunch has learned. New Delhi ordered internet providers to block its website, resulting in patchy access across networks.\n\nThe blocking order was issued on Febru",
      "tags": [
        "Apple",
        "Amazon",
        "Cloud Computing",
        "EVs",
        "Google"
      ]
    },
    {
      "title": "ChatGPT reaches 900M weekly active users",
      "link": "https://techcrunch.com/2026/02/27/chatgpt-reaches-900m-weekly-active-users/",
      "author": "Aisha Malik",
      "date": "2026-02-27T10:25:51-08:00",
      "image": "https://techcrunch.com/wp-content/uploads/2025/02/GettyImages-2195918462.jpg?w=1024",
      "category": "",
      "content": "ChatGPT has reached 900 million weekly active users, OpenAIannouncedFriday, putting the AI chatbot within striking distance of 1 billion. OpenAI also shared that it now has 50 million paying subscribers.\n\n“Subscriber momentum accelerated meaningfully to start the year, with January and February on track to be the largest months for new subscribers in our history,” the company wrote in a blog post. “People use ChatGPT to learn, write, plan, and build. As usage scales, the product improves in ways people feel immediately: faster responses, higher reliability, stronger safety, and more consistent performance.”\n\nThe new weekly active user figure marks a jump of 100 million users from the800 millionthat OpenAI reported in October 2025.\n\nOpenAI shared the new numbers as part of its announcement that it hasraised $110 billionin private funding, marking one of the largest private funding rounds in history. The new funding includes a $50 billion investment from Amazon, along with $30 billion each from Nvidia and SoftBank, at a $730 billion pre-money valuation. The round remains open, and the company expects more investors to join.",
      "excerpt": "ChatGPT has reached 900 million weekly active users, OpenAIannouncedFriday, putting the AI chatbot within striking distance of 1 billion. OpenAI also shared that it now has 50 million paying subscribers.\n\n“Subscriber momentum accelerated meaningfully to start the year, with January and February on t",
      "tags": [
        "Apple",
        "Amazon",
        "Cloud Computing",
        "EVs",
        "Google"
      ]
    }
  ]
}